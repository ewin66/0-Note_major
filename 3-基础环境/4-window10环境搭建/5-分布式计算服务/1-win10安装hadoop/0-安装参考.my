<h1>hadoop-2.7.3 在windows环境下安装</h1>

<p>&nbsp; &nbsp; &nbsp; &nbsp;最近折腾文件系统，用到了hadoop，虽然项目是部署在Linux下的。但自己平时开发用的是windows系统（本人用的是win10 64bit）。为了方便开发和调试，所以打算在windows环境下安装hadoop。&nbsp;</p>

<p>&nbsp; &nbsp; &nbsp; &nbsp;往上找了几篇文章，都说得不是很详细。安装过程中遇到了一些问题，索性自己折腾了一番，终于搞好了。</p>

<p><strong>准备条件：</strong></p>

<p>首先需要下载 hadoop的tar.gz包，这里需要的版本是<a href="http://archive.apache.org/dist/hadoop/core/hadoop-2.7.3/?C=S;O=A">2.7.3</a>，hadooponwindows-master.zip插件支持2.7.1,2.7.3。</p>

<p>然后确保<a href="http://lib.csdn.net/base/operatingsystem" target="_blank" title="操作系统知识库">操作系统</a>是64bit，已安装.netframework，要4.0以上版本，一般现在的windows系统都有自带的。</p>

<p>第三是配置好java环境，至于java环境的配置这里不介绍，百度一下就知道了。我这里用的是JDK1.7.80。</p>

<p><strong>重点</strong>：因为是在windows下面安装的，跟Linux下不一样，所以我们需要windows下运行的链接库。这个库我已经基本配置好，直接覆盖就可以使用了。除了JDK路径，一般不需要改其他东西。</p>

<p><strong>开始：</strong></p>

<p>确保上述的条件以后，我们开始来安装hadoop。</p>

<p>1）解压下载好的 hadoop-2.7.3.tar.gz &nbsp;到某个盘下，注意路径里不要带空格，否则可能会无法正确识别。</p>

<p>2）解压hadooponwindows-master.zip，直接覆盖到hadoop-2.7.3根目录。</p>

<p>3）配置hadoop环境变量（跟配置JAVA环境变量类似）。 创建HADOOP_HOME，另外在Path下添加&nbsp;%HADOOP_HOME%\bin</p>

<p><img alt="" src="http://img.blog.csdn.net/20161209121913975?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29rSnVpcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>

<p><img alt="" src="http://img.blog.csdn.net/20161209122015243?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29rSnVpcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>

<p>4）到hadoop根目录，如果没有data文件夹的话就新建一个，然后在data下分别创建datanode、namenode两个文件夹</p>

<p><img alt="" src="http://img.blog.csdn.net/20161209122236633?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29rSnVpcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>

<p>5）用记事本打开 \hadoop-2.7.3\etc\hadoop\hadoop-env.cmd文件，修改JAVA_HOME为你自己jdk路径。注意：如果你的JDK安装在Program Files目录下，名称用\PROGRA~1\Java 否则中间的空格可能会识别失败。</p>

<p>&nbsp;</p>

<p><img alt="" src="http://img.blog.csdn.net/20161209122539462?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29rSnVpcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>

<p>到这里，配置基本已经完成，如果你想改访问路径，可以到etc/hadoop目录下的core-site.xml文件修改：</p>

<ol start="1">
	<li>&lt;configuration&gt;&nbsp;&nbsp;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;fs.default.name&lt;/name&gt;&nbsp;&nbsp;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;&nbsp;&nbsp;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;&nbsp;&nbsp;</li>
	<li>&lt;/configuration&gt;&nbsp;&nbsp;&nbsp;</li>
</ol>

<p>最后，点击命令提示符（管理员）运行命令提示符，切换到hadoop的安装目录。进行以下操作</p>

<p>1、切换到etc/hadoop目录，运行hadoop-env.cmd</p>

<p>2、格式化HDFS文件系统，切换到bin目录然后执行命令：hdfs&nbsp;namenode&nbsp;-format</p>

<p>到这里，你的hadoop就可以正常使用了。可以查看一下版本 hadoop version</p>

<p><img alt="" src="http://img.blog.csdn.net/20161209131035529?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvS29rSnVpcw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" /></p>

<p><strong>启动：</strong></p>

<p>切换到 sbin目录 执行：start-dfs.cmd&nbsp;</p>
