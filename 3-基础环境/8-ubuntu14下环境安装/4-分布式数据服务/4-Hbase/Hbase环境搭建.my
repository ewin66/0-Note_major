<h1>1. &nbsp;快速单击安装</h1>

<p>在单机安装<a href="http://lib.csdn.net/base/hbase" target="_blank" title="Hbase知识库">Hbase</a>的方法。会引导你通过<strong>shell</strong>创建一个表，插入一行，然后删除它，最后停止Hbase。只要10分钟就可以完成以下的操作。</p>

<h2>1.1下载解压最新版本</h2>

<h3>选择一个&nbsp;<a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank">Apache 下载镜像</a>：<a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank">http://www.apache.org/dyn/closer.cgi/hbase/</a>，下载&nbsp;<em>HBase Releases</em>. 点击&nbsp;stable目录，然后下载后缀为&nbsp;.tar.gz&nbsp;的文件; 例如&nbsp;hbase-0.90.4.tar.gz.</h3>

<p><strong>后面需要安装集群，整合到<a href="http://lib.csdn.net/base/hadoop" target="_blank" title="Hadoop知识库">Hadoop</a>，所以注意选择与hadoop对应的版本：</strong></p>

<p>&nbsp;</p>

<p>选择 Hadoop 版本对HBase部署很关键。下表显示不同HBase支持的Hadoop版本信息。基于HBase版本，应该选择合适的Hadoop版本。我们没有绑定 Hadoop 发行版选择。可以从Apache使用 Hadoop 发行版，或了解一下Hadoop发行商产品：&nbsp;<a href="http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support" target="_blank">http://wiki.apache.org/hadoop/Distributions%20and%20Commercial%20Support</a></p>

<p><strong>Table&nbsp;2.1.&nbsp;Hadoop version support matrix</strong></p>

<table border="1" summary="Hadoop version support matrix">
	<thead>
		<tr>
			<th>&nbsp;</th>
			<th>HBase-0.92.x</th>
			<th>HBase-0.94.x</th>
			<th>HBase-0.96</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Hadoop-0.20.205</td>
			<td>S</td>
			<td>X</td>
			<td>X</td>
		</tr>
		<tr>
			<td>Hadoop-0.22.x</td>
			<td>S</td>
			<td>X</td>
			<td>X</td>
		</tr>
		<tr>
			<td>Hadoop-1.0.x</td>
			<td>S</td>
			<td>S</td>
			<td>S</td>
		</tr>
		<tr>
			<td>Hadoop-1.1.x</td>
			<td>NT</td>
			<td>S</td>
			<td>S</td>
		</tr>
		<tr>
			<td>Hadoop-0.23.x</td>
			<td>X</td>
			<td>S</td>
			<td>NT</td>
		</tr>
		<tr>
			<td>Hadoop-2.x</td>
			<td>X</td>
			<td>S</td>
			<td>S</td>
		</tr>
	</tbody>
</table>

<p>&nbsp;</p>

<table border="0" summary="Simple list">
	<tbody>
		<tr>
			<td>S = supported and tested,支持</td>
		</tr>
		<tr>
			<td>X = not supported,不支持</td>
		</tr>
		<tr>
			<td>NT = not tested enough.可以运行但测试不充分</td>
		</tr>
	</tbody>
</table>

<p>由于 HBase 依赖 Hadoop，它配套发布了一个Hadoop jar 文件在它的&nbsp;lib&nbsp;下。该套装jar仅用于独立模式。在分布式模式下，Hadoop版本必须和HBase下的版本一致。用你运行的分布式Hadoop版本jar文件替换HBase lib目录下的Hadoop jar文件，以避免版本不匹配问题。确认替换了集群中所有HBase下的jar文件。Hadoop版本不匹配问题有不同表现，但看起来都像挂掉了。</p>

<p>&nbsp;</p>

<p><strong>安装：</strong></p>

<p>$ tar xfz hbase-0.90.4.tar.gz<br />
$ cd hbase-0.90.4</p>

<p>&nbsp;</p>

<p>现在你已经可以启动Hbase了。但是你可能需要先编辑&nbsp;conf/hbase-site.xml&nbsp;去配置hbase.rootdir，来选择Hbase将数据写到哪个目录 .</p>

<p>单机配置，只需要如下配置hbase-site.xml：</p>

<ol start="1">
	<li>&lt;?xml&nbsp;version=&quot;1.0&quot;?&gt;&nbsp;&nbsp;</li>
	<li>&lt;?xml-stylesheet&nbsp;type=&quot;text/xsl&quot;&nbsp;href=&quot;configuration.xsl&quot;?&gt;&nbsp;&nbsp;</li>
	<li>&lt;configuration&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hbase.rootdir&lt;/name&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;file:///DIRECTORY/hbase&lt;/value&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;</li>
	<li>&lt;/configuration&gt;&nbsp;&nbsp;</li>
</ol>

<p>&nbsp;</p>

<p>将&nbsp;DIRECTORY&nbsp;替换成你期望写文件的目录. 默认&nbsp;hbase.rootdir&nbsp;是指向&nbsp;/tmp/hbase-${user.name}&nbsp;，也就说你会在重启后丢失数据(重启的时候<a href="http://lib.csdn.net/base/operatingsystem" target="_blank" title="操作系统知识库">操作系统</a>会清理/tmp目录)</p>

<h2>1.2.&nbsp;启动 HBase</h2>

<p>现在启动Hbase:</p>

<pre>
$ ./bin/start-hbase.sh</pre>

<pre>
starting Master, logging to logs/hbase-user-master-example.org.out</pre>

<p>现在你运行的是单机模式的Hbaes。所以的服务都运行在一个JVM上，包括Hbase和Zookeeper。Hbase的日志放在<code>logs</code>目录,当你启动出问题的时候，可以检查这个日志。</p>

<h2>1.3.&nbsp;Hbase Shell 练习</h2>

<p>用<strong>shell</strong>连接你的Hbase</p>

<pre>
$ ./bin/hbase shell</pre>

<pre>
HBase Shell; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands.</pre>

<pre>
Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell</pre>

<pre>
Version: 0.90.0, r1001068, Fri Sep 24 13:55:42 PDT 2010</pre>

<pre>
&nbsp;</pre>

<pre>
hbase(main):001:0&gt; </pre>

<p>输入&nbsp;<strong>help</strong>&nbsp;然后&nbsp;<strong>&lt;RETURN&gt;</strong>&nbsp;可以看到一列shell命令。这里的帮助很详细，要注意的是表名，行和列需要加引号。</p>

<p>创建一个名为&nbsp;<code>test</code>&nbsp;的表，这个表只有一个column family 为&nbsp;<code>cf</code>。可以列出所有的表来检查创建情况，然后插入些值。</p>

<pre>
hbase(main):003:0&gt; create &#39;test&#39;, &#39;cf&#39;</pre>

<pre>
0 row(s) in 1.2200 seconds</pre>

<pre>
hbase(main):003:0&gt; list &#39;table&#39;</pre>

<pre>
test</pre>

<pre>
1 row(s) in 0.0550 seconds</pre>

<pre>
hbase(main):004:0&gt; put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;</pre>

<pre>
0 row(s) in 0.0560 seconds</pre>

<pre>
hbase(main):005:0&gt; put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;</pre>

<pre>
0 row(s) in 0.0370 seconds</pre>

<pre>
hbase(main):006:0&gt; put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;</pre>

<pre>
0 row(s) in 0.0450 seconds</pre>

<p>以上我们分别插入了3行。第一个行key为<code>row1</code>, 列为&nbsp;<code>cf:a</code>， 值是&nbsp;<code>value1</code>。Hbase中的列是由 column family前缀和列的名字组成的，以冒号间隔。例如这一行的列名就是<code>a</code>.</p>

<p>检查插入情况.</p>

<p>Scan这个表，操作如下</p>

<pre>
hbase(main):007:0&gt; scan &#39;test&#39;</pre>

<pre>
ROW&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; COLUMN+CELL</pre>

<pre>
row1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; column=cf:a, timestamp=1288380727188, value=value1</pre>

<pre>
row2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; column=cf:b, timestamp=1288380738440, value=value2</pre>

<pre>
row3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; column=cf:c, timestamp=1288380747365, value=value3</pre>

<pre>
3 row(s) in 0.0590 seconds</pre>

<p>Get一行，操作如下</p>

<pre>
hbase(main):008:0&gt; get &#39;test&#39;, &#39;row1&#39;</pre>

<pre>
COLUMN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CELL</pre>

<pre>
cf:a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; timestamp=1288380727188, value=value1</pre>

<pre>
1 row(s) in 0.0400 seconds</pre>

<p>disable 再 drop 这张表，可以清除你刚刚的操作</p>

<pre>
hbase(main):012:0&gt; disable &#39;test&#39;</pre>

<pre>
0 row(s) in 1.0930 seconds</pre>

<pre>
hbase(main):013:0&gt; drop &#39;test&#39;</pre>

<pre>
0 row(s) in 0.0770 seconds </pre>

<p>关闭shell</p>

<pre>
hbase(main):014:0&gt; exit</pre>

<h2>1.4.&nbsp;停止 HBase</h2>

<p>运行停止脚本来停止HBase.</p>

<pre>
$ ./bin/stop-hbase.sh</pre>

<pre>
stopping hbase...............
</pre>

<p>&nbsp;</p>

<h1>2. &nbsp;Hbase集群安装前注意</h1>

<p><strong>1）&nbsp;&nbsp;<a href="http://lib.csdn.net/base/javase" target="_blank" title="Java SE知识库">Java</a></strong>：（hadoop已经安装了）</p>

<p><strong>2）&nbsp;&nbsp;<a href="http://hadoop.apache.org/common/releases.html" target="_blank">Hadoop 0.20.x</a>&nbsp;/ Hadoop-2.x&nbsp;已经正确安装</strong>，并且可以启动 HDFS 系统, 可参考的Hadoop安装文档：<u>Hadoop集群配置（最全面总结）</u><a href="http://blog.csdn.net/hguisu/article/details/7237395" target="_blank">http://blog.csdn.net/hguisu/article/details/7237395</a></p>

<p>3）&nbsp;&nbsp;ssh 必须安装<strong>ssh</strong>&nbsp;，&nbsp;<strong>sshd</strong>&nbsp;也必须运行，这样Hadoop的脚本才可以远程操控其他的Hadoop和Hbase进程。ssh之间必须都打通，不用密码都可以登录，详细方法可以&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Google一下 (&quot;ssh passwordless login&quot;).</p>

<p>4）&nbsp;&nbsp;NTP：集群的时钟要保证基本的一致。稍有不一致是可以容忍的，但是很大的不一致会 造成奇怪的行为。 运行&nbsp;<a href="http://en.wikipedia.org/wiki/Network_Time_Protocol" target="_blank">NTP</a>&nbsp;或者其他什么东西来同步你的时间.</p>

<p>如果你查询的时候或者是遇到奇怪的故障，可以检查一下系统时间是否正确!</p>

<p>&nbsp;设置集群各个节点时钟：date -s&nbsp;&ldquo;2012-02-13 14:00:00&rdquo;</p>

<p><code>5）&nbsp;&nbsp;</code><code>ulimit</code>&nbsp;和&nbsp;<code>nproc:</code></p>

<p>Base是<a href="http://lib.csdn.net/base/mysql" target="_blank" title="MySQL知识库">数据库</a>，会在同一时间使用很多的文件句柄。大多数<a href="http://lib.csdn.net/base/linux" target="_blank" title="Linux知识库">Linux</a>系统使用的默认值1024是不能满足的，会导致FAQ: Why do I see &quot;java.io.IOException...(Too manyopen files)&quot; in my logs?异常。还可能会发生这样的异常</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: ExceptionincreateBlockOutputStream java.io.EOFException</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient:Abandoning block blk_-6935524980745310745_1391901</p>

<p>所以你需要修改你的最大文件句柄限制。可以设置到10k. 你还需要修改 hbase 用户的 nproc，如果过低会造成 OutOfMemoryError异常。 [2] [3].</p>

<p>需要澄清的，这两个设置是针对操作系统的，不是Hbase本身的。有一个常见的错误是Hbase运行的用户，和设置最大值的用户不是一个用户。在Hbase启动的时候，第一行日志会现在ulimit信息，所以你最好检查一下。&nbsp;</p>

<p>可以先查看当前用户&nbsp;ulimit：</p>

<p>ulimit -n</p>

<p>&nbsp;</p>

<p><strong>设置</strong><code><strong>ulimit:</strong></code></p>

<p><code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code>如果你使用的是Ubuntu,你可以这样设置:</p>

<p>在文件&nbsp;/etc/security/limits.conf&nbsp;添加一行，如:</p>

<p>hadoop&nbsp; -&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nofile&nbsp;32768</p>

<p>可以把&nbsp;hadoop&nbsp;替换成你运行Hbase和Hadoop的用户。如果你用两个用户，你就需要配两个。还有配nproc hard 和 softlimits. 如:</p>

<p>hadoop soft/hard nproc 32000</p>

<p>在&nbsp;/etc/pam.d/common-session&nbsp;加上这一行:</p>

<p>session required&nbsp;pam_limits.so</p>

<p>否则在&nbsp;/etc/security/limits.conf上的配置不会生效.</p>

<p>还有注销再登录，这些配置才能生效!</p>

<p>7 ）修改Hadoop HDFS Datanode同时处理文件的上限：<code>dfs.datanode.max.xcievers</code></p>

<p>一个 Hadoop HDFS Datanode 有一个同时处理文件的上限. 这个参数叫&nbsp;xcievers&nbsp;(Hadoop的作者把这个单词拼错了). 在你加载之前，先确认下你有没有配置这个文件conf/hdfs-site.xml里面的xceivers参数，至少要有4096:</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;property&gt;</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;value&gt;4096&lt;/value&gt;</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;/property&gt;</p>

<p>对于HDFS修改配置要记得重启.</p>

<p>如果没有这一项配置，你可能会遇到奇怪的失败。你会在Datanode的日志中看到xcievers exceeded，但是运行起来会报 missing blocks错误。例如:&nbsp;02/12/1220:10:31 INFO hdfs.DFSClient: Could not obtain blockblk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No livenodes contain current block. Will get new block locations from namenode andretry...</p>

<p>8）继承hadoop安装的说明：</p>

<p>每个机子/etc/hosts</p>

<p>10.64.56.74 &nbsp;node2 （master）</p>

<p>10.64.56.76 &nbsp;node1&nbsp; （slave）</p>

<p>10.64.56.77 &nbsp;node3 （slave）</p>

<p>9) 继续使用hadoop用户安装</p>

<p>Chown &ndash;R hadoop /usr/local/hbase</p>

<h1>3. &nbsp;分布式模式配置</h1>

<h2>3.1配置<code>conf/hbase-env.sh</code></h2>

<p># exportJAVA_HOME=/usr/java/jdk1.6.0/</p>

<p>exportJAVA_HOME=/usr/lib/jvm/java-6-sun-1.6.0.26</p>

<p># Tell HBase whether it should manage it&#39;sown instance of Zookeeper or not.</p>

<p>export HBASE_MANAGES_ZK=true</p>

<p>不管是什么模式，你都需要编辑&nbsp;<code>conf/hbase-env.sh</code>来告知Hbase&nbsp;<strong>java</strong>的安装路径.在这个文件里你还可以设置Hbase的运行环境，诸如 heapsize和其他&nbsp;JVM有关的选项, 还有Log文件地址，等等. 设置&nbsp;<code>JAVA_HOME</code>指向&nbsp;<strong>java</strong>安装的路径.</p>

<p>一个分布式运行的Hbase依赖一个zookeeper集群。所有的节点和客户端都必须能够访问zookeeper。默认的情况下Hbase会管理一个zookeep集群。这个集群会随着Hbase的启动而启动。当然，你也可以自己管理一个zookeeper集群，但需要配置Hbase。你需要修改<code>conf/hbase-env.sh</code>里面的<code>HBASE_MANAGES_ZK</code>&nbsp;来切换。这个值默认是true的，作用是让Hbase启动的时候同时也启动zookeeper.</p>

<p>让Hbase使用一个现有的不被Hbase托管的Zookeep集群，需要设置&nbsp;<code>conf/hbase-env.sh</code>文件中的<code>HBASE_MANAGES_ZK</code>&nbsp;属性为 false</p>

<p># Tell HBase whether it should manage it&#39;s own instanceof Zookeeper or not.</p>

<p>exportHBASE_MANAGES_ZK=false</p>

<h2>3.2 配置conf/hbase-site.xml</h2>

<ol start="1">
	<li>&lt;configuration&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hbase.rootdir&lt;/name&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;hdfs://node1:49002/hbase&lt;/value&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;The&nbsp;directory&nbsp;shared&nbsp;byRegionServers.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;/description&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;true&lt;/value&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;The&nbsp;mode&nbsp;the&nbsp;clusterwill&nbsp;be&nbsp;in.&nbsp;Possible&nbsp;values&nbsp;are&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;false:&nbsp;standalone&nbsp;and&nbsp;pseudo-distributedsetups&nbsp;with&nbsp;managed&nbsp;Zookeeper&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;true:&nbsp;fully-distributed&nbsp;with&nbsp;unmanagedZookeeper&nbsp;Quorum&nbsp;(see&nbsp;hbase-env.sh)&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;/description&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;2222&lt;/value&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;Property&nbsp;fromZooKeeper&#39;s&nbsp;config&nbsp;zoo.cfg.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;port&nbsp;at&nbsp;which&nbsp;the&nbsp;clients&nbsp;willconnect.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/description&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;node1,node2,node3&lt;/value&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;Comma&nbsp;separated&nbsp;listof&nbsp;servers&nbsp;in&nbsp;the&nbsp;ZooKeeper&nbsp;Quorum.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For&nbsp;example,&quot;host1.mydomain.com,host2.mydomain.com,host3.mydomain.com&quot;.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;By&nbsp;default&nbsp;this&nbsp;is&nbsp;set&nbsp;to&nbsp;localhost&nbsp;forlocal&nbsp;and&nbsp;pseudo-distributed&nbsp;modes&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of&nbsp;operation.&nbsp;For&nbsp;a&nbsp;fully-distributedsetup,&nbsp;this&nbsp;should&nbsp;be&nbsp;set&nbsp;to&nbsp;a&nbsp;full&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;list&nbsp;of&nbsp;ZooKeeper&nbsp;quorum&nbsp;servers.&nbsp;IfHBASE_MANAGES_ZK&nbsp;is&nbsp;set&nbsp;in&nbsp;hbase-env.sh&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this&nbsp;is&nbsp;the&nbsp;list&nbsp;of&nbsp;servers&nbsp;which&nbsp;we&nbsp;willstart/stop&nbsp;ZooKeeper&nbsp;on.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/description&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;/home/hadoop/zookeeper&lt;/value&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;Property&nbsp;fromZooKeeper&#39;s&nbsp;config&nbsp;zoo.cfg.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The&nbsp;directory&nbsp;where&nbsp;the&nbsp;snapshot&nbsp;isstored.&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/description&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;</li>
	<li>&nbsp;&nbsp;&lt;/configuration&gt;&nbsp;&nbsp;</li>
</ol>

<p><br />
&nbsp;</p>

<p>要想运行完全分布式模式，加一个属性&nbsp;<code>hbase.cluster.distributed</code>&nbsp;设置为&nbsp;<code>true</code>&nbsp;然后把&nbsp;<code>hbase.rootdir</code>&nbsp;设置为HDFS的NameNode的位置。 例如，你的namenode运行在<strong>node1</strong>，端口是49002 你期望的目录是&nbsp;<code>/hbase</code>,使用如下的配置：hdfs://node1:49002/hbase</p>

<p><strong>hbase.rootdir</strong>：这个目录是region server的共享目录，用来持久化Hbase。URL需要是&#39;完全正确&#39;的，还要包含文件系统的scheme。例如，要表示hdfs中的&#39;/hbase&#39;目录，namenode 运行在node1的49002端口。则需要设置为hdfs://node1:49002/hbase。默认情况下Hbase是写到/tmp的。不改这个配置，数据会在重启的时候丢失。默认:&nbsp;file:///tmp/hbase-${user.name}/hbase</p>

<p><strong>hbase.cluster.distributed</strong>&nbsp;：Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面。</p>

<p>默认:&nbsp;false</p>

<p><strong>在hbase-site.xml配置zookeeper：</strong></p>

<p>当Hbase管理zookeeper的时候，你可以通过修改zoo.cfg来配置zookeeper，</p>

<p>一个更加简单的方法是在&nbsp;conf/hbase-site.xml里面修改zookeeper的配置。Zookeeer的配置是作为property写在&nbsp;hbase-site.xml里面的。</p>

<p><strong>对于zookeepr的配置</strong>，你至少要在&nbsp;hbase-site.xml中列出zookeepr的<strong>ensemble servers</strong>，具体的字段是&nbsp;<strong>hbase.zookeeper.quorum</strong>. 该这个字段的默认值是&nbsp;localhost，这个值对于分布式应用显然是不可以的. (远程连接无法使用)。</p>

<p>&nbsp;</p>

<p><strong>hbase.zookeeper.property.clientPort</strong>：ZooKeeper的zoo.conf中的配置。 客户端连接的端口。</p>

<p>hbase.zookeeper.quorum：Zookeeper集群的地址列表，用逗号分割。例如：&quot;host1.mydomain.com,host2.mydomain.com,host3.mydomain.com&quot;.默认是localhost,是给伪分布式用的。要修改才能在完全分布式的情况下使用。如果在hbase-env.sh设置了HBASE_MANAGES_ZK，这些ZooKeeper节点就会和Hbase一起启动。</p>

<p>默认:&nbsp;localhost</p>

<p>运行一个zookeeper也是可以的，但是在生产环境中，你最好部署3，5，7个节点。部署的越多，可靠性就越高，当然只能部署奇数个，偶数个是不可以的。你需要给每个zookeeper 1G左右的内存，如果可能的话，最好有独立的磁盘。 (独立磁盘可以确保zookeeper是高性能的。).如果你的集群负载很重，不要把Zookeeper和RegionServer运行在同一台机器上面。就像DataNodes 和 TaskTrackers一样</p>

<p><strong>hbase.zookeeper.property.dataDir</strong>：ZooKeeper的zoo.conf中的配置。 快照的存储位置</p>

<p>把ZooKeeper保存数据的目录地址改掉。默认值是&nbsp;/tmp&nbsp;，这里在重启的时候会被操作系统删掉，可以把它修改到&nbsp;/home/hadoop/zookeeper<strong>&nbsp;(这个路径hadoop用户拥有操作权限)</strong></p>

<p>对于独立的Zookeeper，要指明Zookeeper的host和端口。可以在&nbsp;hbase-site.xml中设置, 也可以在Hbase的CLASSPATH下面加一个zoo.cfg配置文件。 HBase 会优先加载&nbsp;zoo.cfg&nbsp;里面的配置，把hbase-site.xml里面的覆盖掉.</p>

<p>参见&nbsp;<a href="http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations" target="_blank">http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations</a>可以查找hbase.zookeeper.property&nbsp;前缀，找到关于zookeeper的配置。</p>

<h2>3.3 配置conf/regionservers</h2>

<p><strong>Node1</strong></p>

<p><strong>Node2</strong></p>

<p>完全分布式模式的还需要修改<code>conf/regionservers</code>.&nbsp;在这里列出了你希望运行的全部&nbsp;HRegionServer，一行写一个host (就像Hadoop里面的&nbsp;<code>slaves</code>&nbsp;一样). 列在这里的server会随着集群的启动而启动，集群的停止而停止.</p>

<p><strong>&nbsp;</strong></p>

<h2><strong>3.4 替换hadoop的jar包</strong></h2>

<p>&nbsp;</p>

<p>hbase基本的配置完了。</p>

<p>查看hbase的lib目录下。</p>

<p>ls lib |grep hadoop</p>

<p><br />
hadoop-annotations-2.1.0-beta.jar<br />
hadoop-auth-2.1.0-beta.jar<br />
hadoop-client-2.1.0-beta.jar<br />
hadoop-common-2.1.0-beta.jar<br />
hadoop-hdfs-2.1.0-beta.jar<br />
hadoop-hdfs-2.1.0-beta-tests.jar<br />
hadoop-mapreduce-client-app-2.1.0-beta.jar<br />
hadoop-mapreduce-client-common-2.1.0-beta.jar<br />
hadoop-mapreduce-client-core-2.1.0-beta.jar<br />
hadoop-mapreduce-client-jobclient-2.1.0-beta.jar<br />
hadoop-mapreduce-client-jobclient-2.1.0-beta-tests.jar<br />
hadoop-mapreduce-client-shuffle-2.1.0-beta.jar<br />
hadoop-yarn-api-2.1.0-beta.jar<br />
hadoop-yarn-client-2.1.0-beta.jar<br />
hadoop-yarn-common-2.1.0-beta.jar<br />
hadoop-yarn-server-common-2.1.0-beta.jar<br />
hadoop-yarn-server-nodemanager-2.1.0-beta.jar</p>

<p>&nbsp;</p>

<p>看到它是基于hadoop2.1.0的，所以我们需要用我们的hadoop2.2.0下的jar包来替换2.1的，保证版本的一致性，hadoop下的jar包都是在$HADOOP_HOME/share/hadoop下的.</p>

<p>&nbsp;</p>

<p>我们先cd 到 /home/hadoop/hbase-0.96.0-hadoop2/lib下运行命令： rm -rf hadoop*.jar删掉所有的hadoop相关的jar包，然后运行：</p>

<p>find /home/hadoop/hadoop-2.2.0/share/hadoop -name &quot;hadoop*jar&quot; | xargs -i cp {}&nbsp;/home/hadoop/hbase-0.96.0-hadoop2/lib/&nbsp;</p>

<p>&nbsp;拷贝所有hadoop2.2.0下的jar包hbase下进行hadoop版本的统一</p>

<p>&nbsp;</p>

<h1>4. &nbsp;运行和确认安装</h1>

<h2>4.1当Hbase托管ZooKeeper的时候</h2>

<p>当Hbase托管ZooKeeper的时候Zookeeper集群的启动是Hbase启动脚本的一部分</p>

<p>首先确认你的HDFS是运行着的。你可以运行<code>HADOOP_HOME</code>中的&nbsp;<code>bin/start-hdfs.sh</code>&nbsp;来启动HDFS.你可以通过<strong>put</strong>命令来<a href="http://lib.csdn.net/base/softwaretest" target="_blank" title="软件测试知识库">测试</a>放一个文件，然后有<strong>get</strong>命令来读这个文件。通常情况下Hbase是不会运行mapreduce的。所以比不需要检查这些。</p>

<p>用如下命令启动Hbase:</p>

<p>bin/start-hbase.sh</p>

<p>这个脚本在<code>HBASE_HOME</code>目录里面。</p>

<p>你现在已经启动Hbase了。Hbase把log记在&nbsp;<code>logs</code>&nbsp;子目录里面. 当Hbase启动出问题的时候，可以看看Log.</p>

<p>Hbase也有一个界面，上面会列出重要的属性。默认是在Master的60010端口上H (HBase RegionServers 会默认绑定 60020端口，在端口60030上有一个展示信息的界面 ).如果Master运行在&nbsp;<code>node1</code>，端口是默认的话，你可以用浏览器在&nbsp;<code>http://node:60010</code>看到主界面. .</p>

<p>一旦Hbase启动，可以看到如何建表，插入数据，scan你的表，还有disable这个表，最后把它删掉。</p>

<p>可以在Hbase Shell停止Hbase</p>

<p>$./bin/stop-hbase.sh</p>

<p>stoppinghbase...............</p>

<p>停止操作需要一些时间，你的集群越大，停的时间可能会越长。如果你正在运行一个分布式的操作，要确认在Hbase彻底停止之前，Hadoop不能停.</p>

<p>&nbsp;</p>

<h2><strong>4.2独立的zookeeper启动，</strong></h2>

<p>除了启动habse，</p>

<p><strong>执行：</strong>bin/start-hbase.sh启动habse</p>

<p>你需要自己去运行zookeeper：</p>

<p>${HBASE_HOME}/bin/hbase-daemons.sh {start,stop} zookeeper</p>

<p>你可以用这条命令启动ZooKeeper而不启动Hbase.&nbsp;HBASE_MANAGES_ZK&nbsp;的值是&nbsp;false， 如果你想在Hbase重启的时候不重启ZooKeeper,你可以这样。</p>

<p>&nbsp;</p>

<h1>5. &nbsp;测试</h1>

<p>&nbsp;</p>

<p>可以使用jps查看进程：在master上：</p>

<p><img alt="" src="http://hi.csdn.net/attachment/201202/13/0_1329122220Xvgw.gif" /></p>

<p>在node2，node3（slave节点）上</p>

<p><img alt="" src="http://hi.csdn.net/attachment/201202/13/0_1329122252R5O1.gif" /></p>

<p>通过浏览器查看60010端口：</p>

<p><img alt="" src="http://hi.csdn.net/attachment/201202/13/0_1329122293KCsk.gif" style="height:394px; width:553px" /></p>

<p>&nbsp;</p>

<p>1. &nbsp;安装中出现的问题</p>

<h2>1 ）</h2>

<p>用./start-hbase.sh启动HBase后，执行hbase shell<br />
# bin/hbase shell<br />
HBase Shell; enter &#39;help&lt;RETURN&gt;&#39; for list of supported commands.<br />
Version: 0.20.6, rUnknown, Thu Oct 28 19:02:04 CST 2010<br />
接着创建表时候出现如下情况：hbase(main):001:0&gt; create &#39;test&#39;,&#39;&#39;c<br />
NativeException: org.apache.hadoop.hbase.MasterNotRunningException: null</p>

<p>jps下，发现主节点上HMaster没有启动，查理HBase log（logs/hbase-hadoop-master-ubuntu.log）里有下面异常：<br />
FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.<br />
java.io.IOException: Call to node1/10.64.56.76:49002 failed on local exception: java.io.EOFException</p>

<p>&nbsp;</p>

<p>解决：</p>

<p>从hadoop_home/下面cp一个hadoop/hadoop-core-0.20.203.0.jar到hbase_home/lib下。</p>

<p>因为Hbase建立在Hadoop之上，所以他用到了hadoop.jar,这个Jar在 lib 里面。这个jar是hbase自己打了branch-0.20-append 补丁的hadoop.jar. Hadoop使用的hadoop.jar和Hbase使用的 必须 一致。所以你需要将 Hbaselib 目录下的hadoop.jar替换成Hadoop里面的那个，防止版本冲突。比方说CDH的版本没有HDFS-724而branch-0.20-append里面有，这个HDFS-724补丁修改了RPC协议。如果不替换，就会有版本冲突，继而造成严重的出错，Hadoop会看起来挂了。</p>

<p>再用./start-hbase.sh启动HBase后，jps下，发现主节点上HMaster还是没有启动，在HBase log里有下面异常：<br />
FATAL org.apache.hadoop.hbase.master.HMaster: Unhandled exception. Starting shutdown.<br />
java.lang.NoClassDefFoundError: org/apache/commons/configuration/Configuration<br />
解决：<br />
在NoClassDefFoundError,缺少 org/apache/commons/configuration/Configuration&nbsp;<br />
果断给他加一个commons-configuration包，<br />
从hadoop_home/lib下面cp一个hadoop/lib/commons-configuration-1.6.jar到hbase_home/lib下。</p>

<p>（集群上所有机子的hbase配置都需要一样）</p>

<p>&nbsp;</p>

<p>创建表报错：</p>

<p>ERROR: java.io.IOException: Table Namespace Manager not ready yet, try again later<br />
at org.apache.hadoop.hbase.master.HMaster.getNamespaceDescriptor(HMaster.java:3101)<br />
at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1738)<br />
at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1777)<br />
at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:38221)<br />
at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2146)<br />
at org.apache.hadoop.hbase.ipc.RpcServer$Handler.run(RpcServer.java:1851)</p>

<p>&nbsp;</p>

<p>解决：</p>

<p>1） 查看集群的所有机器上，</p>

<p>HRegionServer和HQuorumPeer进程是否都启动？</p>

<p>2）查看集群的所有机器的logs是不是有错误消息；</p>

<p>tail -f&nbsp;hbase-hadoop-regionserver-XXX..log&nbsp;</p>

<p>&nbsp;</p>

<h2>2&nbsp; 注意事项：</h2>

<p>&nbsp;1）、先启动hadoop后，再开启hbase<br />
&nbsp;2）、去掉hadoop的安全模式：hadoop dfsadmin -safemode leave<br />
&nbsp;3）、把/etc/hosts里的ubuntu的IP改为服务器当前的IP<br />
&nbsp;4)&nbsp; 、确认hbase的hbase-site.xml中<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &lt;name&gt;hbase.rootdir&lt;/name&gt;<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;value&gt;hdfs://node：49002/hbase&lt;/value&gt;<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 与hadoop的core-site.xml中<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;name&gt;fs.default.name&lt;/name&gt;<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;value&gt;hdfs://node：49002/hbase&lt;/value&gt;<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 红字部分保持一致</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;</p>

<p>&nbsp; &nbsp; &nbsp;否则报错：java.lang.RuntimeException: HMaster Aborted</p>

<p><br />
&nbsp;6)、重新执行./start-hbase.sh之前，先kill掉当前的hbase和zookeeper进程</p>

<p>7）hosts注意顺序：</p>

<p>192.168.1.214 master<br />
192.168.1.205 node1<br />
192.168.1.207 node2<br />
192.168.1.209 node3<br />
192.168.1.205 T205.joy.cc</p>

<p><strong>PS：遇到问题时，先查看logs，很有帮助。</strong></p>

<p>&nbsp;</p>

<p>HBase 官方文档，全面介绍hbase安装配置：</p>

<p><a href="http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations" target="_blank">http://www.yankay.com/wp-content/hbase/book.html#hbase_default_configurations</a></p>
