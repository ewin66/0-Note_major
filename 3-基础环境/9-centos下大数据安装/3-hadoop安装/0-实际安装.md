# centos实际安装hadoop
## 服务器功能规划

|master	|slaveA	|slaveB|
|:-|:-|:-|
|NameNode	|||	 
|DataNode	|DataNode	|DataNode|
|ResourceManage	|SecondaryNameNode||	
|NodeManager	|NodeManager	|NodeManager|

## 安装前设置
在安装Hadoop之前，需要进入Linux环境下，连接Linux使用SSH(安全Shell)。按照下面提供的步骤设立Linux环境。

### 创建用户
在开始时，建议创建一个单独的用户Hadoop以从Unix文件系统隔离Hadoop文件系统。按照下面给出的步骤来创建用户：

使用 “su” 命令开启root .
创建用户从root帐户使用命令 “useradd username”.
现在，可以使用命令打开一个现有的用户帐户“su username”.
打开Linux终端，输入以下命令来创建一个用户。

```
$ su 
password: 
# groupadd hadoop
# useradd hadoop -g hadoop
# passwd hadoop 
New passwd: [这里密码为 hadoop]
Retype new passwd
```

### 创建目录

执行了上面的创建用户的命令，其实这里的文件夹已经有了。跳过

在home目录下新建目录hadoop，注意，用户属组都要为
```
hadoop:hadoop
mkdir /all/hadoop
chown -R hadoop:hadoop /all/hadoop
```
## SSH设置

### SSH安装
检测是否已经安装ssh，本次centos已经安装，故略过。

### SSH登录
然后使用以下方式登陆SSH：
ssh hadoop@10.186.73.242 hadoop为10.186.73.242机器上的用户，需要输入密码。 
ssh hadoop@szvphicprb04240 也可以用主机名代替ip地址
断开连接：exit

### 设置SSH无密码登录
Hadoop集群中的各个机器间会相互地通过SSH访问，每次访问都输入密码是不现实的，所以要配置各个机器间的

### SSH是无密码登录的。

1、 在master上生成公钥(这里以hadoop用户登录)

hadoop# ssh-keygen -t rsa(可以不执行，也许已有了！)
一路回车，都设置为默认值，然后再当前用户的Home目录下的.ssh目录中会生成公钥文件（id_rsa.pub）和私钥文件（id_rsa）。

2、 分发公钥
```
# ssh-copy-id hadoop@szvphicprb04240
# ssh-copy-id hadoop@szvphicprb04238
# ssh-copy-id hadoop@szvphicprb04241
```

这里注意：ssh-copy-id 是将当前用户的公钥分发到指定机器上的指定用户。

例如在master机器上，当前用户执行ssh-copy-id hadoop@slaveA。

当前用户就能通过ssh hadoop@slaveA用hadoop免密账号登录slaveA。

3、 设置slaveA、slaveB到其他机器的无密钥登录

同样的在slaveA、slaveB上生成公钥和私钥后，将公钥分发到三台机器上。

## IP地址配置

修改本机ip地址
vi /etc/network/interfaces

修改本机主机名
vi /etc/hostname （分别设置为master，slaveA，slaveB）

配置主机名与ip的映射
```
vi /etc/hosts

127.0.0.1 localhost
127.0.1.1 ubuntu
127.0.0.1 master

100.109.99.126 szvphicprb04240
10.186.73.242 szvphicprb04238
10.186.77.82 szvphicprb04241


# The following lines are desirable for IPv6 capable hosts
::1 ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
```

## master上安装hadoop

1、下载hadoop
官网下载页 在这里选择合适的版本，然后获取镜像地址，再使用wget下载安装包

wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.9.0/hadoop-2.9.0.tar.gz

2、解压Hadoop
[hadoop]$ tar -zxf /usr/all/nfs/share/hadoop-2.9.0.tar.gz -C /all/hadoop/soft
注意，这里目标位置在主从的几个机器上最好一致。不然报错，暂时不知怎么解决。

3、配置hadoop相关脚本里面的JDK
进入hadoop安装目录下，配置Hadoop JDK路径修改hadoop-env.sh、mapred-env.sh、yarn-env.sh文件中的JDK路径：
```
[hadoop]$ vi etc/hadoop/hadoop-env.sh
[hadoop]$ vi etc/hadoop/mapred-env.sh
[hadoop]$ vi etc/hadoop/yarn-env.sh
```
添加下面这句
```
export JAVA_HOME=/usr/master/a_run/a_envir/java/jdk1.8
```
4、修改配置文件
配置slaves
[hadoop]$ vi etc/hadoop/slaves
添加作为datanode的主机名
```
szvphicprb04240
szvphicprb04238
szvphicprb04241
```
slaves文件是指定HDFS上有哪些DataNode节点。

配置core-site.xml
[hadoop]$ vi etc/hadoop/core-site.xml
```
<configuration>
<property>
<name>fs.defaultFS</name>
<value>hdfs://szvphicprb04240:8020</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/all/hadoop/data/tmp</value>
</property>
</configuration>
```
fs.defaultFS为NameNode的地址。

hadoop.tmp.dir为hadoop临时目录的地址，默认情况下，NameNode和DataNode的数据文件都会存在这个目录下的对应子目录下。应该保证此目录是存在的，如果不存在，先创建。

配置hdfs-site.xml
[hadoop]$ vi etc/hadoop/hdfs-site.xml
```
<configuration>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>szvphicprb04238:50090</value>
</property>
</configuration>
```
dfs.namenode.secondary.http-address是指定secondaryNameNode的http访问地址和端口号，因为在规划中，我们将slaveB规划为SecondaryNameNode服务器。

所以这里设置为：slaveB:50090

配置yarn-site.xml
[hadoop]$ vi etc/hadoop/yarn-site.xml
```
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.resourcemanager.hostname</name>
<value>szvphicprb04240</value>
</property>
<property>
<name>yarn.log-aggregation-enable</name>
<value>true</value>
</property>
<property>
<name>yarn.log-aggregation.retain-seconds</name>
<value>106800</value>
</property>
```
根据规划yarn.resourcemanager.hostname这个指定resourcemanager服务器指向master。

yarn.log-aggregation-enable是配置是否启用日志聚集功能。

yarn.log-aggregation.retain-seconds是配置聚集的日志在HDFS上最多保存多长时间。

配置mapred-site.xml
从mapred-site.xml.template复制一个mapred-site.xml文件。

[hadoop]$ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml
```
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
<property>
<name>mapreduce.jobhistory.address</name>
<value>szvphicprb04240:10020</value>
</property>
<property>
<name>mapreduce.jobhistory.webapp.address</name>
<value>szvphicprb04240:19888</value>
</property>
</configuration>
```
mapreduce.framework.name设置mapreduce任务运行在yarn上。

mapreduce.jobhistory.address是设置mapreduce的历史服务器安装在master机器上。

mapreduce.jobhistory.webapp.address是设置历史服务器的web页面地址和端口号。

5、添加系统路径
vi ~/.bashrc

根据实际情况添加下面配置
```
export JAVA_HOME=/all/java/jdk1.8.0
export CLASSPATH=.:$JAVA_HOME/lib/*jar
export PATH=$JAVA_HOME/bin:$PATH

export HADOOP_HOME=/all/hadoop/hadoop-2.9.0/
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_ROOT_LOGGER=INFO,console
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib:$HADOOP_COMMON_LIB_NATIVE_DIR"

```
##　slave上安装hadoop

创建目录
首先，在slave机器上设置好目录。
```
mkdir /all/hadoop
chown -R hadoop:hadoop /all/hadoop
```

拷贝hadoop文件
复制Master节点的hadoop文件夹到SlaveA和SlaveB上。下面的s大写，不知道为毛。
```
scp -r /all/hadoop hadoop@SlaveA:/home
scp -r /all/hadoop hadoop@SlaveB:/home
```
如果有部分文件需传输，可参考下面
```
scp -r /all/hadoop/data hadoop@SlaveB:/all/hadoop/
scp -r /all/hadoop/soft hadoop@SlaveB:/all/hadoop/

scp -r /all/hadoop/soft/hadoop-3.0.3/etc hadoop@SlaveA:/all/hadoop/soft/hadoop-3.0.3
scp -r /all/hadoop/soft/hadoop-3.0.3/etc hadoop@SlaveB:/all/hadoop/soft/hadoop-3.0.3
```
拷贝系统配置
```
scp -r /all/hadoop/.bashrc hadoop@SlaveB:/all/hadoop/
```

格式NameNode

注意，有几台机子是NameNode，就都执行下！！

在NameNode机器上执行格式化：
```
[hadoop]$ /all/hadoop/soft/hadoop-3.0.3/bin/hdfs namenode –format
```
## 启动集群
1、 启动HDFS
```
[hadoop]$ /all/hadoop/soft/hadoop-3.0.3/sbin/start-dfs.sh
```
2、 启动YARN
```
[hadoop]$ /all/hadoop/soft/hadoop-3.0.3/sbin/start-yarn.sh
```
在slaveA上启动ResourceManager:
```
[hadoop@slaveA]$ /all/hadoop/soft/hadoop-3.0.3/sbin/yarn-daemon.sh start resourcemanager
enter image description here
```

### 安装验证-访问管理界面

#### 查看HDFS Web页面

hadoop3之后，这里的访问端口变成了 9870

之前的版本的话，例如本次安装，路径为下面这个：

[http://100.109.99.126:50070](http://100.109.99.126:50070)

#### 查看YARN Web 页面

[http://100.109.99.126:8088/cluster](http://100.109.99.126:8088/cluster)

### 测试Job

我们这里用hadoop自带的wordcount例子来在本地模式下测试跑mapreduce。

1、 准备mapreduce输入文件wc.input
[hadoop@bigdata-senior01 modules]$ cat /opt/data/wc.input
hadoop mapreduce hive
hbase spark storm
sqoop hadoop hive
spark hadoop

2、 在HDFS创建输入目录input
[hadoop@bigdata-senior01 hadoop-2.5.0]$ bin/hdfs dfs -mkdir /input

3、 将wc.input上传到HDFS
[hadoop@bigdata-senior01 hadoop-2.5.0]$ bin/hdfs dfs -put /opt/data/wc.input /input/wc.input

4、 运行hadoop自带的mapreduce Demo
[hadoop@bigdata-senior01 hadoop-2.5.0]$ bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0.jar wordcount /input/wc.input /output
enter image description here

5、 查看输出文件
[hadoop@bigdata-senior01 hadoop-2.5.0]$ bin/hdfs dfs -ls /output
Found 2 items
-rw-r--r-- 3 hadoop supergroup 0 2016-07-14 16:36 /output/_SUCCESS
-rw-r--r-- 3 hadoop supergroup 60 2016-07-14 16:36 /output/part-r-00000
