<h1>第五部分 高效并发</h1>

<p>第12章 Java内存模型与线程<br />
第13章 线程安全与锁优化<br />
第12章 Java内存模型与线程<br />
并发处理的广泛应用是使得Amdahl定律代替摩尔定律[1]成为计算机性能发展源动力的根<br />
本原因，也是人类“压榨”计算机运算能力的最有力武器。<br />
12.1 概述<br />
多任务处理在现代计算机操作系统中几乎已是一项必备的功能了。 在许多情况下，让计<br />
算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计<br />
算机的运算速度与它的存储和通信子系统速度的差距太大，大量的时间都花费在磁盘I/O、<br />
网络通信或者数据库访问上。 如果不希望处理器在大部分时间里都处于等待其他资源的状<br />
态，就必须使用一些手段去把处理器的运算能力“压榨”出来，否则就会造成很大的浪费，而<br />
让计算机同时处理几项任务则是最容易想到、 也被证明是非常有效的“压榨”手段。<br />
除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务则是另一<br />
个更具体的并发应用场景。 衡量一个服务性能的高低好坏，每秒事务处理数（Transactions<br />
Per Second,TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而<br />
TPS值与程序的并发能力又有非常密切的关系。 对于计算量相同的任务，程序线程并发协调<br />
得越有条不紊，效率自然就会越高；反之，线程之间频繁阻塞甚至死锁，将会大大降低程序<br />
的并发能力。<br />
服务端是Java语言最擅长的领域之一，这个领域的应用占了Java应用中最大的一块份<br />
额[2]，不过如何写好并发应用程序却又是服务端程序开发的难点之一，处理好并发方面的问<br />
题通常需要更多的编码经验来支持。 幸好Java语言和虚拟机提供了许多工具，把并发编程的<br />
门槛降低了不少。 并且各种中间件服务器、 各类框架都努力地替程序员处理尽可能多的线程<br />
并发细节，使得程序员在编码时能更关注业务逻辑，而不是花费大部分时间去关注此服务会<br />
同时被多少人调用、 如何协调硬件资源。 无论语言、 中间件和框架如何先进，开发人员都不<br />
能期望它们能独立完成所有并发处理的事情，了解并发的内幕也是成为一个高级程序员不可<br />
缺少的课程。<br />
“高效并发”是本书讲解Java虚拟机的最后一部分，将会向读者介绍虚拟机如何实现多线<br />
程、 多线程之间由于共享和竞争数据而导致的一系列问题及解决方案。<br />
[1]Amdahl定律通过系统中并行化与串行化的比重来描述多处理器系统能获得的运算加速能<br />
力，摩尔定律则用于描述处理器晶体管数量与运行效率之间的发展关系。 这两个定律的更替<br />
代表了近年来硬件发展从追求处理器频率到追求多核心并行处理的发展过程。<br />
[2]必须以代码的总体规模来衡量，服务端应用不能与JavaCard、 移动终端这些领域去比绝对<br />
数量。<br />
12.2 硬件的效率与一致性<br />
在正式讲解Java虚拟机并发相关的知识之前，我们先花费一点时间去了解一下物理计算<br />
机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发<br />
的处理方案对于虚拟机的实现也有相当大的参考意义。<br />
“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的效能”之间的因果<br />
关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中一个重要的<br />
复杂性来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内<br />
存交互，如读取运算数据、 存储运算结果等，这个I/O操作是很难消除的（无法仅靠寄存器<br />
来完成所有运算任务）。 由于计算机的存储设备与处理器的运算速度有几个数量级的差距，<br />
所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存<br />
（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运<br />
算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存<br />
读写了。<br />
基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统<br />
带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。 在多处<br />
理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main<br />
Memory），如图12-1所示。 当多个处理器的运算任务都涉及同一块主内存区域时，将可能导<br />
致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为<br />
准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根<br />
据协议来进行操作，这类协议有MSI、 MESI（Illinois Protocol）、 MOSI、 Synapse、 Firefly及<br />
Dragon Protocol等。 在本章中将会多次提到的“内存模型”一词，可以理解为在特定的操作协<br />
议下，对特定的内存或高速缓存进行读写访问的过程抽象。 不同架构的物理机器可以拥有不<br />
一样的内存模型，而Java虚拟机也有自己的内存模型，并且这里介绍的内存访问操作与硬件<br />
的缓存访问操作具有很高的可比性。<br />
图 12-1 处理器、 高速缓存、 主内存间的交互关系<br />
除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可<br />
能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序<br />
执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算<br />
的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务<br />
的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。 与处理器的乱序执行优化类<br />
似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化。<br />
12.3 Java内存模型<br />
Java虚拟机规范中试图定义一种Java内存模型[1]（Java Memory Model,JMM）来屏蔽掉各<br />
种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访<br />
问效果。 在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模<br />
型，因此，会由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正<br />
常，而在另外一套平台上并发访问却经常出错，因此在某些场景就必须针对不同的平台来编<br />
写程序。<br />
定义Java内存模型并非一件容易的事情，这个模型必须定义得足够严谨，才能让Java的<br />
并发内存访问操作不会产生歧义；但是，也必须定义得足够宽松，使得虚拟机的实现有足够<br />
的自由空间去利用硬件的各种特性（寄存器、 高速缓存和指令集中某些特有的指令）来获取<br />
更好的执行速度。 经过长时间的验证和修补，在JDK 1.5（实现了JSR-133[2]）发布后，Java内<br />
存模型已经成熟和完善起来了。<br />
12.3.1 主内存与工作内存<br />
Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储<br />
到内存和从内存中取出变量这样的底层细节。 此处的变量（Variables）与Java编程中所说的<br />
变量有所区别，它包括了实例字段、 静态字段和构成数组对象的元素，但不包括局部变量与<br />
方法参数，因为后者是线程私有的[3]，不会被共享，自然就不会存在竞争问题。 为了获得较<br />
好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内<br />
存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。<br />
Java内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与<br />
介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部<br />
分）。 每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类<br />
比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝[4]，线程对变量的<br />
所有操作（读取、 赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量[5]。<br />
不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主<br />
内存来完成，线程、 主内存、 工作内存三者的交互关系如图12-2所示。<br />
这里所讲的主内存、 工作内存与本书第2章所讲的Java内存区域中的Java堆、 栈、 方法区<br />
等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起<br />
来，那从变量、 主内存、 工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据<br />
部分[6]，而工作内存则对应于虚拟机栈中的部分区域。 从更低层次上说，主内存就直接对应<br />
于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措<br />
施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是<br />
工作内存。<br />
图 12-2 线程、 主内存、 工作内存三者的交互关系（请与图12-1对比）<br />
[1]本书中的Java内存模型都特指目前正在使用的，即在JDK 1.2之后建立起来并在JDK 1.5中<br />
完备过的内存模型。<br />
[2]JSR-133：Java Memory Model and Thread Specification Revision（Java内存模型和线程规范<br />
修订）。<br />
[3]此处请读者注意区分概念：如果局部变量是一个reference类型，它引用的对象在Java堆中<br />
可被各个线程共享，但是reference本身在Java栈的局部变量表中，它是线程私有的。<br />
[4]有不少读者会对这段描述中的“拷贝副本”提出疑问，如“假设线程中访问一个10MB的对<br />
象，也会把这10MB的内存复制一份拷贝出来吗？”，事实上并不会如此，这个对象的引用、<br />
对象中某个在线程访问到的字段是有可能存在拷贝的，但不会有虚拟机实现成把整个对象拷<br />
贝A一次。<br />
[5]根据Java虚拟机规范的规定，volatile变量依然有工作内存的拷贝，但是由于它特殊的操作<br />
顺序性规定（后文会讲到），所以看起来如同直接在主内存中读写访问一般，因此这里的描<br />
述对于volatile也并不存在例外。<br />
[6]除了实例数据，Java堆还保存了对象的其他信息，对于HotSpot虚拟机来讲，有Mark<br />
Word（存储对象哈希码、 GC标志、 GC年龄、 同步锁等信息）、 Klass Point（指向存储类型<br />
元数据的指针）及一些用于字节对齐补白的填充数据（如果实例数据刚好满足8字节对齐的<br />
话，则可以不存在补白）。<br />
12.3.2 内存间交互操作<br />
关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内<br />
存、 如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来<br />
完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、 不可再分的（对于double<br />
和long类型的变量来说，load、 store、 read和write操作在某些平台上允许有例外，这个问题<br />
在12.3.4节再讲）[1]。<br />
lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。<br />
unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放<br />
后的变量才可以被其他线程锁定。<br />
read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内<br />
存中，以便随后的load动作使用。<br />
load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工<br />
作内存的变量副本中。<br />
use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引<br />
擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。<br />
assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内<br />
存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。<br />
store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存<br />
中，以便随后的write操作使用。<br />
write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入<br />
主内存的变量中。<br />
如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果<br />
要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。 注意，Java内存模型<br />
只要求上述两个操作必须按顺序执行，而没有保证是连续执行。 也就是说，read与load之<br />
间、 store与write之间是可插入其他指令的，如对主内存中的变量a、 b进行访问时，一种可能<br />
出现顺序是read a、 read b、 load b、 load a。 除此之外，Java内存模型还规定了在执行上述8种<br />
基本操作时必须满足如下规则：<br />
不允许read和load、 store和write操作之一单独出现，即不允许一个变量从主内存读取了<br />
但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现。<br />
不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该<br />
变化同步回主内存。<br />
不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步<br />
回主内存中。<br />
一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化<br />
（load或assign）的变量，换句话说，就是对一个变量实施use、 store操作之前，必须先执行<br />
过了assign和load操作。<br />
一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线<br />
程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。<br />
如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这<br />
个变量前，需要重新执行load或assign操作初始化变量的值。<br />
如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去<br />
unlock一个被其他线程锁定住的变量。<br />
对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、 write操<br />
作）。<br />
这8种内存访问操作以及上述规则限定，再加上稍后介绍的对volatile的一些特殊规定，<br />
就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。 由于这种定义相当严谨<br />
但又十分烦琐，实践起来很麻烦，所以在12.3.6节中笔者将介绍这种定义的一个等效判断原<br />
则——先行发生原则，用来确定一个访问在并发环境下是否安全。<br />
[1]基于理解难度和严谨性考虑，最新的JSR-133文档中，已经放弃采用这8种操作去定义Java<br />
内存模型的访问协议了（仅是描述方式改变了，Java内存模型并没有改变）。<br />
12.3.3 对于volatile型变量的特殊规则<br />
关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制，但是它并不容易完全被<br />
正确、 完整地理解，以至于许多程序员都习惯不去使用它，遇到需要处理多线程数据竞争问<br />
题的时候一律使用synchronized来进行同步。 了解volatile变量的语义对后面了解多线程操作的<br />
其他特性很有意义，在本节中我们将多花费一些时间去弄清楚volatile的语义到底是什么。<br />
Java内存模型对volatile专门定义了一些特殊的访问规则，在介绍这些比较拗口的规则定<br />
义之前，笔者先用不那么正式但通俗易懂的语言来介绍一下这个关键字的作用。<br />
当一个变量定义为volatile之后，它将具备两种特性，第一是保证此变量对所有线程的可<br />
见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以<br />
立即得知的。 而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来<br />
完成，例如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线<br />
程A回写完成了之后再从主内存进行读取操作，新变量值才会对线程B可见。<br />
关于volatile变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile变量<br /> 

对所有线程是立即可见的，对volatile变量所有的写操作都能立刻反应到其他线程之中，换句<br />
话说，volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是安全<br />
的”。 这句话的论据部分并没有错，但是其论据并不能得出“基于volatile变量的运算在并发下<br />
是安全的”这个结论。 volatile变量在各个线程的工作内存中不存在一致性问题（在各个线程<br />
的工作内存中，volatile变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执<br />
行引擎看不到不一致的情况，因此可以认为不存在一致性问题），但是Java里面的运算并非<br />
原子操作，导致volatile变量的运算在并发下一样是不安全的，我们可以通过一段简单的演示<br />
来说明原因，请看代码清单12-1中演示的例子。<br />
代码清单12-1 volatile的运算<br />
/**<br />
*volatile变量自增运算测试<br />
**<br />
@author zzm<br />
*/<br />
public class VolatileTest{<br />
public static volatile int race=0；<br />
public static void increase（）{<br />
race++；<br />
}p<br />
rivate static final int THREADS_COUNT=20；<br />
public static void main（String[]args）{<br />
Thread[]threads=new Thread[THREADS_COUNT]；<br />
for（int i=0；i＜THREADS_COUNT；i++）{<br />
threads[i]=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
for（int i=0；i＜10000；i++）{<br />
increase（）；<br />
}}}<br />
）；<br />
threads[i].start（）；<br />
}/<br />
/等待所有累加线程都结束<br />
while（Thread.activeCount（）＞1）<br />
Thread.yield（）；<br />
System.out.println（race）；<br />
}} 这<br />
段代码发起了20个线程，每个线程对race变量进行10000次自增操作，如果这段代码能<br />
够正确并发的话，最后输出的结果应该是200000。 读者运行完这段代码之后，并不会获得期<br />
望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于200000的数字，<br />
这是为什么呢？<br />
问题就出现在自增运算“race++”之中，我们用Javap反编译这段代码后会得到代码清单<br />
12-2，发现只有一行代码的increase（）方法在Class文件中是由4条字节码指令构成的（return<br />
指令不是由race++产生的，这条指令可以不计算），从字节码层面上很容易就分析出并发失<br />
败的原因了：当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此<br />
时是正确的，但是在执行iconst_1、 iadd这些指令的时候，其他线程可能已经把race的值加大<br />
了，而在操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值<br />
同步回主内存之中。<br />
代码清单12-2 VolatileTest的字节码<br />
public static void increase（）；<br />
Code：<br />
Stack=2，Locals=0，Args_size=0<br />
0：getstatic#13；//Field race：I<br />
3：iconst_1<br />
4：iadd<br />
5：putstatic#13；//Field race：I<br />
8：return<br />
LineNumberTable：<br />
line 14：0<br />
line 15：8<br />
客观地说，笔者在此使用字节码来分析并发问题，仍然是不严谨的，因为即使编译出来<br />
只有一条字节码指令，也并不意味执行这条指令就是一个原子操作。 一条字节码指令在解释<br />
执行时，解释器将要运行许多行代码才能实现它的语义，如果是编译执行，一条字节码指令<br />
也可能转化成若干条本地机器码指令，此处使用-XX：+PrintAssembly参数输出反汇编来分析<br />
会更加严谨一些，但考虑到读者阅读的方便，并且字节码已经能说明问题，所以此处使用字<br />
节码来分析。<br />
由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通<br />
过加锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性。<br />
运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。<br />
变量不需要与其他的状态变量共同参与不变约束。<br />
而在像如下的代码清单12-3所示的这类场景就很适合使用volatile变量来控制并发，当<br />
shutdown（）方法被调用时，能保证所有线程中执行的doWork（）方法都立即停下来。<br />
代码清单12-3 volatile的使用场景<br />
volatile boolean shutdownRequested；<br />
public void shutdown（）{<br />
shutdownRequested=true；<br />
}p<br />
ublic void doWork（）{<br />
while（！shutdownRequested）{<br />
//do stuff<br />
}} 使<br />
用volatile变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法<br />
的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的<br />
顺序与程序代码中的执行顺序一致。 因为在一个线程的方法执行过程中无法感知到这点，这<br />
也就是Java内存模型中描述的所谓的“线程内表现为串行的语义”（Within-Thread As-If-Serial<br />
Semantics）。<br />
上面的描述仍然不太容易理解，我们还是继续通过一个例子来看看为何指令重排序会干<br />
扰程序的并发执行，演示程序如代码清单12-4所示。<br />
代码清单12-4 指令重排序<br />
Map configOptions；<br />
char[]configText；<br />
//此变量必须定义为volatile<br />
volatile boolean initialized=false；<br />
//假设以下代码在线程A中执行<br />
//模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用<br />
configOptions=new HashMap（）；<br />
configText=readConfigFile（fileName）；<br />
processConfigOptions（configText,configOptions）；<br />
initialized=true；<br />
//假设以下代码在线程B中执行<br />
//等待initialized为true，代表线程A已经把配置信息初始化完成<br />
while（！initialized）{<br />
sleep（）；<br />
}/<br />
/使用线程A中初始化好的配置信息<br />
doSomethingWithConfig（）；<br />
代码清单12-4中的程序是一段伪代码，其中描述的场景十分常见，只是我们在处理配置<br />
文件时一般不会出现并发而已。 如果定义initialized变量时没有使用volatile修饰，就可能会由<br />
于指令重排序的优化，导致位于线程A中最后一句的代码“initialized=true”被提前执行（这里<br />
虽然使用Java作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这句话<br />
对应的汇编代码被提前执行），这样在线程B中使用配置信息的代码就可能出现错误，而<br />
volatile关键字则可以避免此类情况的发生[1]。<br />
指令重排序是并发编程中最容易让开发人员产生疑惑的地方，除了上面伪代码的例子之<br />
外，笔者再举一个可以实际操作运行的例子来分析volatile关键字是如何禁止指令重排序优化<br />
的。 代码清单12-5是一段标准的DCL单例代码，可以观察加入volatile和未加入volatile关键字<br />
时所生成汇编代码的差别（如何获得JIT的汇编代码，请参考4.2.7节）。<br />
代码清单12-5 DCL单例模式<br />
public class Singleton{<br />
private volatile static Singleton instance；<br />
public static Singleton getInstance（）{<br />
if（instance==null）{<br />
synchronized（Singleton.class）{<br />
if（instance==null）{<br />
instance=new Singleton（）；<br />
}}}r<br />
eturn instance；<br />
}p<br />
ublic static void main（String[]args）{<br />
Singleton.getInstance（）；<br />
} 编<br />
译后，这段代码对instance变量赋值部分如代码清单12-6所示。<br />
代码清单12-6<br />
0x01a3de0f：mov$0x3375cdb0，%esi；……beb0cd75 33<br />
；{oop（'Singleton'）}<br />
0x01a3de14：mov%eax，0x150（%esi）；……89865001 0000<br />
0x01a3de1a：shr$0x9，%esi；……c1ee09<br />
0x01a3de1d：movb$0x0，0x1104800（%esi）；……c6860048 100100<br />
0x01a3de24：lock addl$0x0，（%esp）；……f0830424 00<br />
；*putstatic instance<br />
；-<br />
Singleton：getInstance@24<br />
通过对比就会发现，关键变化在于有volatile修饰的变量，赋值后（前面<br />
mov%eax，0x150（%esi）这句便是赋值操作）多执行了一个“lock addl ＄0x0，（%esp）”操<br />
作，这个操作相当于一个内存屏障（Memory Barrier或Memory Fence，指重排序时不能把后<br />
面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；<br />
但如果有两个或更多CPU访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来<br />
保证一致性了。 这句指令中的“addl ＄0x0，（%esp）”（把ESP寄存器的值加0）显然是一个<br />
空操作（采用这个空操作而不是空操作指令nop是因为IA32手册规定lock前缀不允许配合nop<br />
指令使用），关键在于lock前缀，查询IA32手册，它的作用是使得本CPU的Cache写入了内<br />
存，该写入动作也会引起别的CPU或者别的内核无效化（Invalidate）其Cache，这种操作相<br />
当于对Cache中的变量做了一次前面介绍Java内存模式中所说的“store和write”操作[2]。 所以通<br />
过这样一个空操作，可让前面volatile变量的修改对其他CPU立即可见。<br />
那为何说它禁止指令重排序呢？从硬件架构上讲，指令重排序是指CPU采用了允许将多<br />
条指令不按程序规定的顺序分开发送给各相应电路单元处理。 但并不是说指令任意重<br />
排，CPU需要能正确处理指令依赖情况以保障程序能得出正确的执行结果。 譬如指令1把地<br />
址A中的值加10，指令2把地址A中的值乘以2，指令3把地址B中的值减去3，这时指令1和指<br />
令2是有依赖的，它们之间的顺序不能重排——（A+10）*2与A*2+10显然不相等，但指令3<br />
可以重排到指令1、 2之前或者中间，只要保证CPU执行后面依赖到A、 B值的操作时能获取到<br />
正确的A和B值即可。 所以在本内CPU中，重排序看起来依然是有序的。 因此，lock<br />
addl＄0x0，（%esp）指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，<br />
这样便形成了“指令重排序无法越过内存屏障”的效果。<br />
解决了volatile的语义问题，再来看看在众多保障并发安全的工具中选用volatile的意义<br />
——它能让我们的代码比使用其他的同步工具更快吗？在某些情况下，volatile的同步机制的<br />
性能确实要优于锁（使用synchronized关键字或java.util.concurrent包里面的锁），但是由于虚<br />
拟机对锁实行的许多消除和优化，使得我们很难量化地认为volatile就会比synchronized快多<br />
少。 如果让volatile自己与自己比较，那可以确定一个原则：volatile变量读操作的性能消耗与<br />
普通变量几乎没有什么差别，但是写操作则可能会慢一些，因为它需要在本地代码中插入许<br />
多内存屏障指令来保证处理器不发生乱序执行。 不过即便如此，大多数场景下volatile的总开<br />
销仍然要比锁低，我们在volatile与锁之中选择的唯一依据仅仅是volatile的语义能否满足使用<br />
场景的需求。<br />
在本节的最后，我们回头看一下Java内存模型中对volatile变量定义的特殊规则。 假定T<br />
表示一个线程，V和W分别表示两个volatile型变量，那么在进行read、 load、 use、 assign、<br />
store和write操作时需要满足如下规则：<br />
只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动<br />
作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行<br />
load动作。 线程T对变量V的use动作可以认为是和线程T对变量V的load、 read动作相关联，必<br />
须连续一起出现（这条规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的<br />
值，用于保证能看见其他线程对变量V所做的修改后的值）。<br />
只有当线程T对变量V执行的前一个动作是assign的时候，线程T才能对变量V执行store动<br />
作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行<br />
assign动作。 线程T对变量V的assign动作可以认为是和线程T对变量V的store、 write动作相关<br />
联，必须连续一起出现（这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内<br />
存中，用于保证其他线程可以看到自己对变量V所做的修改）。<br />
假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load<br />
或store动作，假定动作P是和动作F相应的对变量V的read或write动作；类似的，假定动作B是<br />
线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假<br />
定动作Q是和动作G相应的对变量W的read或write动作。 如果A先于B，那么P先于Q（这条规<br />
则要求volatile修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相<br />
同）。<br />
[1]volatile屏蔽指令重排序的语义在JDK 1.5中才被完全修复，此前的JDK中即使将变量声明<br />
为volatile也仍然不能完全避免重排序所导致的问题（主要是volatile变量前后的代码仍然存在<br />
重排序问题），这点也是在JDK 1.5之前的Java中无法安全地使用DCL（双锁检测）来实现单<br />
例模式的原因。<br />
[2]Doug Lea列出了各种处理器架构下的内存屏障指令：<br />
http://g.oswego.edu/dl/jmm/cookbook.html。<br />
12.3.4 对于long和double型变量的特殊规则<br />
Java内存模型要求lock、 unlock、 read、 load、 assign、 use、 store、 write这8个操作都具有<br />
原子性，但是对于64位的数据类型（long和double），在模型中特别定义了一条相对宽松的<br />
规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进<br />
行，即允许虚拟机实现选择可以不保证64位数据类型的load、 store、 read和write这4个操作的<br />
原子性，这点就是所谓的long和double的非原子性协定（Nonatomic Treatment ofdouble and<br />
long Variables）。<br />
如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它<br />
们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改值<br />
的代表了“半个变量”的数值。<br />
不过这种读取到“半个变量”的情况非常罕见（在目前商用Java虚拟机中不会出现），因<br />
为Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但允许虚拟机<br />
选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现。 在实际开发<br />
中，目前各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，<br />
因此我们在编写代码时一般不需要把用到的long和double变量专门声明为volatile。<br />
12.3.5 原子性、 可见性与有序性<br />
介绍完Java内存模型的相关操作和规则，我们再整体回顾一下这个模型的特征。 Java内<br />
存模型是围绕着在并发过程中如何处理原子性、 可见性和有序性这3个特征来建立的，我们<br />
逐个来看一下哪些操作实现了这3个特性。<br />
原子性（Atomicity）：由Java内存模型来直接保证的原子性变量操作包括read、 load、<br />
assign、 use、 store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的（例<br />
外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些<br />
几乎不会发生的例外情况）。<br />
如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了<br />
lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，<br />
但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这<br />
两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块<br />
之间的操作也具备原子性。<br />
可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即<br />
得知这个修改。 上文在讲解volatile变量的时候我们已详细讨论过这一点。 Java内存模型是通<br />
过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作<br />
为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此，普通变量与<br />
volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前<br />
立即从主内存刷新。 因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则<br />
不能保证这一点。<br />
除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。 同步块的<br />
可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、<br />
write操作）”这条规则获得的，而final关键字的可见性是指：被final修饰的字段在构造器中一<br />
旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事<br />
情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看<br />
见final字段的值。 如代码清单12-7所示，变量i与j都具备可见性，它们无须同步就能被其他<br />
线程正确访问。<br />
代码清单12-7 final与可见性<br />
public static final int i；<br />
public final int j；<br />
static{<br />
i=0；<br />
//do something<br />
}{/<br />
/也可以选择在构造函数中初始化<br />
j=0；<br />
//do something<br />
} 有<br />
序性（Ordering）：Java内存模型的有序性在前面讲解volatile时也详细地讨论过<br />
了，Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有<br />
序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。 前半句是指“线程内表<br />
现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象<br />
和“工作内存与主内存同步延迟”现象。<br />
Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile<br />
关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻<br />
只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同<br />
步块只能串行地进入。<br />
介绍完并发中3种重要的特性后，读者有没有发现synchronized关键字在需要这3种特性的<br />
时候都可以作为其中一种的解决方案？看起来很“万能”吧。 的确，大部分的并发控制操作都<br />
能使用synchronized来完成。 synchronized的“万能”也间接造就了它被程序员滥用的局面，<br />
越“万能”的并发控制，通常会伴随着越大的性能影响，这点我们将在第13章讲解虚拟机锁优<br />
化时再介绍。<br />
12.3.6 先行发生原则<br />
如果Java内存模型中所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操<br />
作将会变得很烦琐，但是我们在编写Java并发代码的时候并没有感觉到这一点，这是因为<br />
Java语言中有一个“先行发生”（happens-before）的原则。 这个原则非常重要，它是判断数据<br />
是否存在竞争、 线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地<br />
解决并发环境下两个操作之间是否可能存在冲突的所有问题。<br />
现在就来看看“先行发生”原则指的是什么。 先行发生是Java内存模型中定义的两项操作<br />
之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产<br />
生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、 发送了消息、 调用了<br />
方法等。 这句话不难理解，但它意味着什么呢？我们可以举个例子来说明一下，如代码清单<br />
12-8中所示的这3句伪代码。<br />
代码清单12-8 先行发生原则示例1<br />
//以下操作在线程A中执行<br />
i=1；<br />
//以下操作在线程B中执行<br />
j=i；<br />
//以下操作在线程C中执行<br />
i=2；<br />
假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那么可以确定在线程B的操作<br />
执行后，变量j的值一定等于1，得出这个结论的依据有两个：一是根据先行发生原<br />
则，“i=1”的结果可以被观察到；二是线程C还没“登场”，线程A操作结束之后没有其他线程<br />
会修改变量i的值。 现在再来考虑线程C，我们依然保持线程A和线程B之间的先行发生关<br />
系，而线程C出现在线程A和线程B的操作之间，但是线程C与线程B没有先行发生关系，那j<br />
的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B<br />
观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性。<br />
下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器<br />
协助就已经存在，可以在编码中直接使用。 如果两个操作之间的关系不在此列，并且无法从<br />
下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。<br />
程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面<br />
的操作先行发生于书写在后面的操作。 准确地说，应该是控制流顺序而不是程序代码顺序，<br />
因为要考虑分支、 循环等结构。<br />
管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock<br />
操作。 这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序。<br />
volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面<br />
对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序。<br />
线程启动规则（Thread Start Rule）：Thread对象的start（）方法先行发生于此线程的每<br />
一个动作。<br />
线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的<br />
终止检测，我们可以通过Thread.join（）方法结束、 Thread.isAlive（）的返回值等手段检测<br />
到线程已经终止执行。<br />
线程中断规则（Thread Interruption Rule）：对线程interrupt（）方法的调用先行发生于被<br />
中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted（）方法检测到是否有<br />
中断发生。<br />
对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发<br />
生于它的finalize（）方法的开始。<br />
传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就<br />
可以得出操作A先行发生于操作C的结论。<br />
Java语言无须任何同步手段保障就能成立的先行发生规则就只有上面这些了，笔者演示<br />
一下如何使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是<br />
线程是否安全，读者还可以从下面这个例子中感受一下“时间上的先后顺序”与“先行发生”之<br />
间有什么不同。 演示例子如代码清单12-9所示。<br />
代码清单12-9 先行发生原则示例2<br />
private int value=0；<br />
pubilc void setValue（int value）{<br />
this.value=value；<br />
}p<br />
ublic int getValue（）{<br />
return value；<br />
} 代<br />
码清单12-9中显示的是一组再普通不过的getter/setter方法，假设存在线程A和B，线程<br />
A先（时间上的先后）调用了“setValue（1）”，然后线程B调用了同一个对象<br />
的“getValue（）”，那么线程B收到的返回值是什么？<br />
我们依次分析一下先行发生原则中的各项规则，由于两个方法分别由线程A和线程B调<br />
用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生<br />
lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被volatile关键字修饰，所<br />
以volatile变量规则不适用；后面的线程启动、 终止、 中断规则和对象终结规则也和这里完全<br />
没有关系。 因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们<br />
可以判定尽管线程A在操作时间上先于线程B，但是无法确定线程B中“getValue（）”方法的<br />
返回结果，换句话说，这里面的操作不是线程安全的。<br />
那怎么修复这个问题呢？我们至少有两种比较简单的方案可以选择：要么把getter/setter<br />
方法都定义为synchronized方法，这样就可以套用管程锁定规则；要么把value定义为volatile<br />
变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样<br />
就可以套用volatile变量规则来实现先行发生关系。<br />
通过上面的例子，我们可以得出结论：一个操作“时间上的先发生”不代表这个操作会<br />
是“先行发生”，那如果一个操作“先行发生”是否就能推导出这个操作必定是“时间上的先发<br />
生”呢？很遗憾，这个推论也是不成立的，一个典型的例子就是多次提到的“指令重排序”，<br />
演示例子如代码清单12-10所示。<br />
代码清单12-10 先行发生原则示例3<br />
//以下操作在同一个线程中执行<br />
int i=1；<br />
int j=2；<br />
代码清单12-10的两条赋值语句在同一个线程之中，根据程序次序规则，“int i=1”的操作<br />
先行发生于“int j=2”，但是“int j=2”的代码完全可能先被处理器执行，这并不影响先行发生原<br />
则的正确性，因为我们在这条线程之中没有办法感知到这点。<br />
上面两个例子综合起来证明了一个结论：时间先后顺序与先行发生原则之间基本没有太<br />
大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发<br />
生原则为准。<br />
12.4 Java与线程<br />
并发不一定要依赖多线程（如PHP中很常见的多进程并发），但是在Java里面谈论并<br />
发，大多数都与线程脱不开关系。 既然我们这本书探讨的话题是Java虚拟机的特性，那讲到<br />
Java线程，我们就从Java线程在虚拟机中的实现开始讲起。<br />
12.4.1 线程的实现<br />
我们知道，线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资<br />
源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、 文件I/O等），又可以<br />
独立调度（线程是CPU调度的基本单位）。<br />
主流的操作系统都提供了线程实现，Java语言则提供了在不同硬件和操作系统平台下对<br />
线程操作的统一处理，每个已经执行start（）且还未结束的java.lang.Thread类的实例就代表<br />
了一个线程。 我们注意到Thread类与大部分的Java API有显著的差别，它的所有关键方法都<br />
是声明为Native的。 在Java API中，一个Native方法往往意味着这个方法没有使用或无法使用<br />
平台无关的手段来实现（当然也可能是为了执行效率而使用Native方法，不过，通常最高效<br />
率的手段也就是平台相关的手段）。 正因为如此，作者把本节的标题定为“线程的实现”而不<br />
是“Java线程的实现”。<br />
实现线程主要有3种方式：使用内核线程实现、 使用用户线程实现和使用用户线程加轻<br />
量级进程混合实现。<br />
1.使用内核线程实现<br />
内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支<br />
持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行<br />
调度，并负责将线程的任务映射到各个处理器上。 每个内核线程可以视为内核的一个分身，<br />
这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（MultiThreads Kernel）。<br />
程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进<br />
程（Light Weight Process,LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻<br />
量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。 这种轻量<br />
级进程与内核线程之间1:1的关系称为一对一的线程模型，如图12-3所示。<br />
图 12-3 轻量级进程与内核线程之间1:1的关系<br />
由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级<br />
进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限<br />
性：首先，由于是基于内核线程实现的，所以各种线程操作，如创建、 析构及同步，都需要<br />
进行系统调用。 而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（Kernel<br />
Mode）中来回切换。 其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进<br />
程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是<br />
有限的。<br />
2.使用用户线程实现<br />
从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（User<br />
Thread,UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实<br />
现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制。<br />
而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存<br />
在的实现。 用户线程的建立、 同步、 销毁和调度完全在用户态中完成，不需要内核的帮助。<br />
如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，<br />
也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。 这<br />
种进程与用户线程之间1：N的关系称为一对多的线程模型，如图12-4所示。<br />
图 12-4 进程与用户线程之间1：N的关系<br />
使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有<br />
的线程操作都需要用户程序自己处理。 线程的创建、 切换和调度都是需要考虑的问题，而且<br />
由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、 “多处理器系统中如何<br />
将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。 因而使用<br />
用户线程实现的程序一般都比较复杂[1]，除了以前在不支持多线程的操作系统中（如DOS）<br />
的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java、<br />
Ruby等语言都曾经使用过用户线程，最终又都放弃使用它。<br />
3.使用用户线程加轻量级进程混合实现<br />
线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用<br />
户线程一起使用的实现方式。 在这种混合实现下，既存在用户线程，也存在轻量级进程。 用<br />
户线程还是完全建立在用户空间中，因此用户线程的创建、 切换、 析构等操作依然廉价，并<br />
且可以支持大规模的用户线程并发。 而操作系统提供支持的轻量级进程则作为用户线程和内<br />
核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的<br />
系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。 在这种混合模<br />
式中，用户线程与轻量级进程的数量比是不定的，即为N：M的关系，如图12-5所示，这种<br />
就是多对多的线程模型。<br />
许多UNIX系列的操作系统，如Solaris、 HP-UX等都提供了N：M的线程模型实现。<br />
图 12-5 用户线程与轻量级进程之间N：M的关系<br />
4.Java线程的实现<br />
Java线程在JDK 1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，<br />
而在JDK 1.2中，线程模型替换为基于操作系统原生线程模型来实现。 因此，在目前的JDK版<br />
本中，操作系统支持怎样的线程模型，在很大程度上决定了Java虚拟机的线程是怎样映射<br />
的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定Java线程需要使用哪<br />
种线程模型来实现。 线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码<br />
和运行过程来说，这些差异都是透明的。<br />
对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型实现的，一条<br />
Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统提供的线程模型就是一对<br />
一的[2]。<br />
而在Solaris平台中，由于操作系统的线程特性可以同时支持一对一（通过Bound Threads<br />
或Alternate Libthread实现）及多对多（通过LWP/Thread Based Synchronization实现）的线程模<br />
型，因此在Solaris版的JDK中也对应提供了两个平台专有的虚拟机参数：-XX：<br />
+UseLWPSynchronization（默认值）和-XX：+UseBoundThreads来明确指定虚拟机使用哪种线<br />
程模型。<br />
[1]此处所讲的“复杂”与“程序自己完成线程操作”，并不限制程序中必须编写了复杂的实现用<br />
户线程的代码，使用用户线程的程序，很多都依赖特定的线程库来完成基本的线程操作，这<br />
些复杂性都封装在线程库之中。<br />
[2]Windows下有纤程包（Fiber Package），Linux下也有NGPT（在2.4内核的年代）来实现<br />
N：M模型，但是它们都没有成为主流。<br />
12.4.2 Java线程调度<br />
线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同<br />
式线程调度（Cooperative Threads-Scheduling）和抢占式线程调度（Preemptive ThreadsScheduling）。<br />
如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的<br />
工作执行完了之后，要主动通知系统切换到另外一个线程上。 协同式多线程的最大好处是实<br />
现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可<br />
知的，所以没有什么线程同步的问题。 Lua语言中的“协同例程”就是这类实现。 它的坏处也<br />
很明显：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程<br />
切换，那么程序就会一直阻塞在那里。 很久以前的Windows 3.x系统就是使用协同式来实现<br />
多进程多任务的，相当不稳定，一个进程坚持不让出CPU执行时间就可能会导致整个系统崩<br />
溃。<br />
如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切<br />
换不由线程本身来决定（在Java中，Thread.yield（）可以让出执行时间，但是要获取执行时<br />
间的话，线程本身是没有什么办法的）。 在这种实现线程调度的方式下，线程的执行时间是<br />
系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢<br />
占式调度[1]。 与前面所说的Windows 3.x的例子相对，在Windows 9x/NT内核中就是使用抢占<br />
式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程“杀掉”，<br />
而不至于导致系统崩溃。<br />
虽然Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配<br />
一点执行时间，另外的一些线程则可以少分配一点——这项操作可以通过设置线程优先级来<br />
完成。 Java语言一共设置了10个级别的线程优先级（Thread.MIN_PRIORITY至<br />
Thread.MAX_PRIORITY），在两个线程同时处于Ready状态时，优先级越高的线程越容易被<br />
系统选择执行。<br />
不过，线程优先级并不是太靠谱，原因是Java的线程是通过映射到系统的原生线程上来<br />
实现的，所以线程调度最终还是取决于操作系统，虽然现在很多操作系统都提供线程优先级<br />
的概念，但是并不见得能与Java线程的优先级一一对应，如Solaris中有2147483648（232）种<br />
优先级，但Windows中就只有7种，比Java线程优先级多的系统还好说，中间留下一点空位就<br />
可以了，但比Java线程优先级少的系统，就不得不出现几个优先级相同的情况了，表12-1显<br />
示了Java线程优先级与Windows线程优先级之间的对应关系，Windows平台的JDK中使用了除<br />
THREAD_PRIORITY_IDLE之外的其余6种线程优先级。<br />
上文说到“线程优先级并不是太靠谱”，不仅仅是说在一些平台上不同的优先级实际会变<br />
得相同这一点，还有其他情况让我们不能太依赖优先级：优先级可能会被系统自行改变。 例<br />
如，在Windows系统中存在一个称为“优先级推进器”（Priority Boosting，当然它可以被关闭<br />
掉）的功能，它的大致作用就是当系统发现一个线程执行得特别“勤奋努力”的话，可能会越<br />
过线程优先级去为它分配执行时间。 因此，我们不能在程序中通过优先级来完全准确地判断<br />
一组状态都为Ready的线程将会先执行哪一个。<br />
[1]在JDK后续版本中有可能会提供协程（Coroutines）方式来进行多任务处理，相关资料可<br />
参见：http://wikis.sun.com/display/mlvm/Coroutines。<br />
12.4.3 状态转换<br />
Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种<br />
状态，这5种状态分别如下。<br />
新建（New）：创建后尚未启动的线程处于这种状态。<br />
运行（Runable）：Runable包括了操作系统线程状态中的Running和Ready，也就是处于此<br />
状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间。<br />
无限期等待（Waiting）：处于这种状态的线程不会被分配CPU执行时间，它们要等待被<br />
其他线程显式地唤醒。 以下方法会让线程陷入无限期的等待状态：<br />
●没有设置Timeout参数的Object.wait（）方法。<br />
●没有设置Timeout参数的Thread.join（）方法。<br />
●LockSupport.park（）方法。<br />
限期等待（Timed Waiting）：处于这种状态的线程也不会被分配CPU执行时间，不过无<br />
须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。 以下方法会让线程<br />
进入限期等待状态：<br />
●Thread.sleep（）方法。<br />
●设置了Timeout参数的Object.wait（）方法。<br />
●设置了Timeout参数的Thread.join（）方法。<br />
●LockSupport.parkNanos（）方法。<br />
●LockSupport.parkUntil（）方法。<br />
阻塞（Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等<br />
待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状<br />
态”则是在等待一段时间，或者唤醒动作的发生。 在程序等待进入同步区域的时候，线程将<br />
进入这种状态。<br />
结束（Terminated）：已终止线程的线程状态，线程已经结束执行。<br />
上述5种状态在遇到特定事件发生的时候将会互相转换，它们的转换关系如图12-6所<br />
示。<br />
图 12-6 线程状态转换关系<br />
12.5 本章小结<br />
本章中，我们首先了解了虚拟机Java内存模型的结构及操作，然后讲解了原子性、 可见<br />
性、 有序性在Java内存模型中的体现，最后介绍了先行发生原则的规则及使用。 另外，我们<br />
还了解了线程在Java语言之中是如何实现的。<br />
关于“高效并发”这个话题，在本章中主要介绍了虚拟机如何实现“并发”，在第13章中，<br />
我们的主要关注点将是虚拟机如何实现“高效”，以及虚拟机对我们编写的并发代码提供了什<br />
么样的优化手段。<br />
第13章 线程安全与锁优化<br />
并发处理的广泛应用是使得Amdahl定律代替摩尔定律成为计算机性能发展源动力的根本<br />
原因，也是人类“压榨”计算机运算能力的最有力武器。<br />
13.1 概述<br />
在软件业发展的初期，程序编写都是以算法为核心的，程序员会把数据和过程分别作为<br />
独立的部分来考虑，数据代表问题空间中的客体，程序代码则用于处理这些数据，这种思维<br />
方式直接站在计算机的角度去抽象问题和解决问题，称为面向过程的编程思想。 与此相对的<br />
是，面向对象的编程思想是站在现实世界的角度去抽象和解决问题，它把数据和行为都看做<br />
是对象的一部分，这样可以让程序员能以符合现实世界的思维方式来编写和组织程序。<br />
面向过程的编程思想极大地提升了现代软件开发的生产效率和软件可以达到的规模，但<br />
是现实世界与计算机世界之间不可避免地存在一些差异。 例如，人们很难想象现实中的对象<br />
在一项工作进行期间，会被不停地中断和切换，对象的属性（数据）可能会在中断期间被修<br />
改和变“脏”，而这些事件在计算机世界中则是很正常的事情。 有时候，良好的设计原则不得<br />
不向现实做出一些让步，我们必须让程序在计算机中正确无误地运行，然后再考虑如何将代<br />
码组织得更好，让程序运行得更快。 对于这部分的主题“高效并发”来讲，首先需要保证并发<br />
的正确性，然后在此基础上实现高效。 本章先从如何保证并发的正确性和如何实现线程安全<br />
讲起。<br />
13.2 线程安全<br />
“线程安全”这个名称，相信稍有经验的程序员都会听说过，甚至在代码编写和走查的时<br />
候可能还会经常挂在嘴边，但是如何找到一个不太拗口的概念来定义线程安全却不是一件容<br />
易的事情，笔者尝试在Google中搜索它的概念，找到的是类似于“如果一个对象可以安全地<br />
被多个线程同时使用，那它就是线程安全的”这样的定义——并不能说它不正确，但是人们<br />
无法从中获取到任何有用的信息。<br />
笔者认为《 Java Concurrency In Practice》 的作者Brian Goetz对“线程安全”有一个比较恰当<br />
的定义：“当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交<br />
替执行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象<br />
的行为都可以获得正确的结果，那这个对象是线程安全的”。<br />
这个定义比较严谨，它要求线程安全的代码都必须具备一个特征：代码本身封装了所有<br />
必要的正确性保障手段（如互斥同步等），令调用者无须关心多线程的问题，更无须自己采<br />
取任何措施来保证多线程的正确调用。 这点听起来简单，但其实并不容易做到，在大多数场<br />
景中，我们都会将这个定义弱化一些，如果把“调用这个对象的行为”限定为“单次调用”，这<br />
个定义的其他描述也能够成立的话，我们就可以称它是线程安全了，为什么要弱化这个定<br />
义，现在暂且放下，稍后再详细探讨。<br />
13.2.1 Java语言中的线程安全<br />
我们已经有了线程安全的一个抽象定义，那接下来就讨论一下在Java语言中，线程安全<br />
具体是如何体现的？有哪些操作是线程安全的？我们这里讨论的线程安全，就限定于多个线<br />
程之间存在共享数据访问这个前提，因为如果一段代码根本不会与其他线程共享数据，那么<br />
从线程安全的角度来看，程序是串行执行还是多线程执行对它来说是完全没有区别的。<br />
为了更加深入地理解线程安全，在这里我们可以不把线程安全当做一个非真即假的二元<br />
排他选项来看待，按照线程安全的“安全程度”由强至弱来排序，我们[1]可以将Java语言中各种<br />
操作共享的数据分为以下5类：不可变、 绝对线程安全、 相对线程安全、 线程兼容和线程对<br />
立。<br />
1.不可变<br />
在Java语言中（特指JDK 1.5以后，即Java内存模型被修正之后的Java语言），不可变<br />
（Immutable）的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需<br />
要再采取任何的线程安全保障措施，在第12章我们谈到final关键字带来的可见性时曾经提到<br />
过这一点，只要一个不可变的对象被正确地构建出来（没有发生this引用逃逸的情况），那<br />
其外部的可见状态永远也不会改变，永远也不会看到它在多个线程之中处于不一致的状态。<br />
“不可变”带来的安全性是最简单和最纯粹的。<br />
Java语言中，如果共享数据是一个基本数据类型，那么只要在定义时使用final关键字修<br />
饰它就可以保证它是不可变的。 如果共享数据是一个对象，那就需要保证对象的行为不会对<br />
其状态产生任何影响才行，如果读者还没想明白这句话，不妨想一想java.lang.String类的对<br />
象，它是一个典型的不可变对象，我们调用它的substring（）、 replace（）和concat（）这些<br />
方法都不会影响它原来的值，只会返回一个新构造的字符串对象。<br />
保证对象行为不影响自己状态的途径有很多种，其中最简单的就是把对象中带有状态的<br />
变量都声明为final，这样在构造函数结束之后，它就是不可变的，例如代码清单13-1中<br />
java.lang.Integer构造函数所示的，它通过将内部状态变量value定义为final来保障状态不变。<br />
代码清单13-1 JDK中Integer类的构造函数<br />
/**<br />
*The value of the＜code＞Integer＜/code＞.<br />
*@serial<br />
*/<br />
private final int value；<br />
/**<br />
*Constructs a newly allocated＜code＞Integer＜/code＞object that<br />
*represents the specified＜code＞int＜/code＞value.<br />
**<br />
@param value the value to be represented by the<br />
*＜code＞Integer＜/code＞object.<br />
*/<br />
public Integer（int value）{<br />
this.value=value；<br />
} 在<br />
Java API中符合不可变要求的类型，除了上面提到的String之外，常用的还有枚举类<br />
型，以及java.lang.Number的部分子类，如Long和Double等数值包装类型，BigInteger和<br />
BigDecimal等大数据类型；但同为Number的子类型的原子类AtomicInteger和AtomicLong则并<br />
非不可变的，读者不妨看看这两个原子类的源码，想一想为什么。<br />
2.绝对线程安全<br />
绝对的线程安全完全满足Brian Goetz给出的线程安全的定义，这个定义其实是很严格<br />
的，一个类要达到“不管运行时环境如何，调用者都不需要任何额外的同步措施”通常需要付<br />
出很大的，甚至有时候是不切实际的代价。 在Java API中标注自己是线程安全的类，大多数<br />
都不是绝对的线程安全。 我们可以通过Java API中一个不是“绝对线程安全”的线程安全类来<br />
看看这里的“绝对”是什么意思。<br />
如果说java.util.Vector是一个线程安全的容器，相信所有的Java程序员对此都不会有异<br />
议，因为它的add（）、 get（）和size（）这类方法都是被synchronized修饰的，尽管这样效<br />
率很低，但确实是安全的。 但是，即使它所有的方法都被修饰成同步，也不意味着调用它的<br />
时候永远都不再需要同步手段了，请看一下代码清单13-2中的测试代码。<br />
代码清单13-2 对Vector线程安全的测试<br />
private static Vector＜Integer＞vector=new Vector＜Integer＞（）；<br />
public static void main（String[]args）{<br />
while（true）{<br />
for（int i=0；i＜10；i++）{<br />
vector.add（i）；<br />
}T<br />
hread removeThread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
for（int i=0；i＜vector.size（）；i++）{<br />
vector.remove（i）；<br />
}}}<br />
）；<br />
Thread printThread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
for（int i=0；i＜vector.size（）；i++）{<br />
System.out.println（（vector.get（i）））；<br />
}}}<br />
）；<br />
removeThread.start（）；<br />
printThread.start（）；<br />
//不要同时产生过多的线程，否则会导致操作系统假死<br />
while（Thread.activeCount（）＞20）；<br />
}}<br />
运行结果如下：<br />
Exception in thread"Thread-132"java.lang.ArrayIndexOutOfBoundsException：<br />
Array index out of range：17<br />
at java.util.Vector.remove（Vector.java：777）<br />
at org.fenixsoft.mulithread.VectorTest$1.run（VectorTest.java：21）<br />
at java.lang.Thread.run（Thread.java：662）<br />
很明显，尽管这里使用到的Vector的get（）、 remove（）和size（）方法都是同步的，<br />
但是在多线程的环境中，如果不在方法调用端做额外的同步措施的话，使用这段代码仍然是<br />
不安全的，因为如果另一个线程恰好在错误的时间里删除了一个元素，导致序号i已经不再<br />
可用的话，再用i访问数组就会抛出一个ArrayIndexOutOfBoundsException。 如果要保证这段代<br />
码能正确执行下去，我们不得不把removeThread和printThread的定义改成如代码清单13-3所<br />
示的样子。<br />
代码清单13-3 必须加入同步以保证Vector访问的线程安全性<br />
Thread removeThread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
synchronized（vector）{<br />
for（int i=0；i＜vector.size（）；i++）{<br />
vector.remove（i）；<br />
}}}}<br />
）；<br />
Thread printThread=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
synchronized（vector）{<br />
for（int i=0；i＜vector.size（）；i++）{<br />
System.out.println（（vector.get（i）））；<br />
}}}}<br />
）；<br />
3.相对线程安全<br />
相对的线程安全就是我们通常意义上所讲的线程安全，它需要保证对这个对象单独的操<br />
作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对于一些特定顺序的连<br />
续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。 上面代码清单13-2<br />
和代码清单13-3就是相对线程安全的明显的案例。<br />
在Java语言中，大部分的线程安全类都属于这种类型，例如Vector、 HashTable、<br />
Collections的synchronizedCollection（）方法包装的集合等。<br />
4.线程兼容<br />
线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段<br />
来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时<br />
候指的是这一种情况。 Java API中大部分的类都是属于线程兼容的，如与前面的Vector和<br />
HashTable相对应的集合类ArrayList和HashMap等。<br />
5.线程对立<br />
线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代<br />
码。 由于Java语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，<br />
而且通常都是有害的，应当尽量避免。<br />
一个线程对立的例子是Thread类的suspend（）和resume（）方法，如果有两个线程同时<br />
持有一个线程对象，一个尝试去中断线程，另一个尝试去恢复线程，如果并发进行的话，无<br />
论调用时是否进行了同步，目标线程都是存在死锁风险的，如果suspend（）中断的线程就是<br />
即将要执行resume（）的那个线程，那就肯定要产生死锁了。 也正是由于这个原<br />
因，suspend（）和resume（）方法已经被JDK声明废弃（@Deprecated）了。 常见的线程对立<br />
的操作还有System.setIn（）、 Sytem.setOut（）和System.runFinalizersOnExit（）等。<br />
[1]这种划分方法也是Brian Goetz在IBM developWorkers上发表的一篇论文中提出的，这里<br />
写“我们”纯粹是笔者下笔行文中的语言用法。<br />
13.2.2 线程安全的实现方法<br />
了解了什么是线程安全之后，紧接着的一个问题就是我们应该如何实现线程安全，这听<br />
起来似乎是一件由代码如何编写来决定的事情，确实，如何实现线程安全与代码编写有很大<br />
的关系，但虚拟机提供的同步和锁机制也起到了非常重要的作用。 本节中，代码编写如何实<br />
现线程安全和虚拟机如何实现同步与锁这两者都会有所涉及，相对而言更偏重后者一些，只<br />
要读者了解了虚拟机线程安全手段的运作过程，自己去思考代码如何编写并不是一件困难的<br />
事情。<br />
1.互斥同步<br />
互斥同步（Mutual Exclusion＆Synchronization）是常见的一种并发正确性保障手段。 同步<br />
是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个（或者是一些，<br />
使用信号量的时候）线程使用。 而互斥是实现同步的一种手段，临界区（Critical<br />
Section）、 互斥量（Mutex）和信号量（Semaphore）都是主要的互斥实现方式。 因此，在这<br />
4个字里面，互斥是因，同步是果；互斥是方法，同步是目的。<br />
在Java中，最基本的互斥同步手段就是synchronized关键字，synchronized关键字经过编译<br />
之后，会在同步块的前后分别形成monitorenter和monitorexit这两个字节码指令，这两个字节<br />
码都需要一个reference类型的参数来指明要锁定和解锁的对象。 如果Java程序中的<br />
synchronized明确指定了对象参数，那就是这个对象的reference；如果没有明确指定，那就根<br />
据synchronized修饰的是实例方法还是类方法，去取对应的对象实例或Class对象来作为锁对<br />
象。<br />
根据虚拟机规范的要求，在执行monitorenter指令时，首先要尝试获取对象的锁。 如果这<br />
个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加1，相应的，在<br />
执行monitorexit指令时会将锁计数器减1，当计数器为0时，锁就被释放。 如果获取对象锁失<br />
败，那当前线程就要阻塞等待，直到对象锁被另外一个线程释放为止。<br />
在虚拟机规范对monitorenter和monitorexit的行为描述中，有两点是需要特别注意的。 首<br />
先，synchronized同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。 其<br />
次，同步块在已进入的线程执行完之前，会阻塞后面其他线程的进入。 第12章讲过，Java的<br />
线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一个线程，都需要操作系统来<br />
帮忙完成，这就需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。<br />
对于代码简单的同步块（如被synchronized修饰的getter（）或setter（）方法），状态转换消<br />
耗的时间有可能比用户代码执行的时间还要长。 所以synchronized是Java语言中一个重量级<br />
（Heavyweight）的操作，有经验的程序员都会在确实必要的情况下才使用这种操作。 而虚拟<br />
机本身也会进行一些优化，譬如在通知操作系统阻塞线程之前加入一段自旋等待过程，避免<br />
频繁地切入到核心态之中。<br />
除了synchronized之外，我们还可以使用java.util.concurrent（下文称J.U.C）包中的重入锁<br />
（ReentrantLock）来实现同步，在基本用法上，ReentrantLock与synchronized很相似，他们都<br />
具备一样的线程重入特性，只是代码写法上有点区别，一个表现为API层面的互斥锁<br />
（lock（）和unlock（）方法配合try/finally语句块来完成），另一个表现为原生语法层面的互<br />
斥锁。 不过，相比synchronized,ReentrantLock增加了一些高级功能，主要有以下3项：等待可<br />
中断、 可实现公平锁，以及锁可以绑定多个条件。<br />
等待可中断是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等<br />
待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。<br />
公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而<br />
非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。<br />
synchronized中的锁是非公平的，ReentrantLock默认情况下也是非公平的，但可以通过带布尔<br />
值的构造函数要求使用公平锁。<br />
锁绑定多个条件是指一个ReentrantLock对象可以同时绑定多个Condition对象，而在<br />
synchronized中，锁对象的wait（）和notify（）或notifyAll（）方法可以实现一个隐含的条<br />
件，如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则<br />
无须这样做，只需要多次调用newCondition（）方法即可。<br />
如果需要使用上述功能，选用ReentrantLock是一个很好的选择，那如果是基于性能考虑<br />
呢？关于synchronized和ReentrantLock的性能问题，Brian Goetz对这两种锁在JDK 1.5与单核处<br />
理器，以及JDK 1.5与双Xeon处理器环境下做了一组吞吐量对比的实验[1]，实验结果如图13-1<br />
和图13-2所示。<br />
图 13-1 JDK 1.5、 单核处理器下两种锁的吞吐量对比<br />
从图13-1和图13-2可以看出，多线程环境下synchronized的吞吐量下降得非常严重，而<br />
ReentrantLock则能基本保持在同一个比较稳定的水平上。 与其说ReentrantLock性能好，还不<br />
如说synchronized还有非常大的优化余地。 后续的技术发展也证明了这一点，JDK 1.6中加入<br />
了很多针对锁的优化措施（13.3节我们就会讲解这些优化措施），JDK 1.6发布之后，人们就<br />
发现synchronized与ReentrantLock的性能基本上是完全持平了。 因此，如果读者的程序是使用<br />
JDK 1.6或以上部署的话，性能因素就不再是选择ReentrantLock的理由了，虚拟机在未来的性<br />
能改进中肯定也会更加偏向于原生的synchronized，所以还是提倡在synchronized能实现需求<br />
的情况下，优先考虑使用synchronized来进行同步。<br />
图 13-2 JDK 1.5、 双Xeon处理器下两种锁的吞吐量对比<br />
2.非阻塞同步<br />
互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也称<br />
为阻塞同步（Blocking Synchronization）。 从处理问题的方式上说，互斥同步属于一种悲观的<br />
并发策略，总是认为只要不去做正确的同步措施（例如加锁），那就肯定会出现问题，无论<br />
共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会<br />
优化掉很大一部分不必要的加锁）、 用户态核心态转换、 维护锁计数器和检查是否有被阻塞<br />
的线程需要唤醒等操作。 随着硬件指令集的发展，我们有了另外一个选择：基于冲突检测的<br />
乐观并发策略，通俗地说，就是先进行操作，如果没有其他线程争用共享数据，那操作就成<br />
功了；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施<br />
就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，<br />
因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。<br />
为什么笔者说使用乐观并发策略需要“硬件指令集的发展”才能进行呢？因为我们需要操<br />
作和冲突检测这两个步骤具备原子性，靠什么来保证呢？如果这里再使用互斥同步来保证就<br />
失去意义了，所以我们只能靠硬件来完成这件事情，硬件保证一个从语义上看起来需要多次<br />
操作的行为只通过一条处理器指令就能完成，这类指令常用的有：<br />
测试并设置（Test-and-Set）。<br />
获取并增加（Fetch-and-Increment）。<br />
交换（Swap）。<br />
比较并交换（Compare-and-Swap，下文称CAS）。<br />
加载链接/条件存储（Load-Linked/Store-Conditional，下文称LL/SC）。<br />
其中，前面的3条是20世纪就已经存在于大多数指令集之中的处理器指令，后面的两条<br />
是现代处理器新增的，而且这两条指令的目的和功能是类似的。 在IA64、 x86指令集中有<br />
cmpxchg指令完成CAS功能，在sparc-TSO也有casa指令实现，而在ARM和PowerPC架构下，<br />
则需要使用一对ldrex/strex指令来完成LL/SC的功能。<br />
CAS指令需要有3个操作数，分别是内存位置（在Java中可以简单理解为变量的内存地<br />
址，用V表示）、 旧的预期值（用A表示）和新值（用B表示）。 CAS指令执行时，当且仅当<br />
V符合旧预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新<br />
了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。<br />
在JDK 1.5之后，Java程序中才可以使用CAS操作，该操作由sun.misc.Unsafe类里面的<br />
compareAndSwapInt（）和compareAndSwapLong（）等几个方法包装提供，虚拟机在内部对<br />
这些方法做了特殊处理，即时编译出来的结果就是一条平台相关的处理器CAS指令，没有方<br />
法调用的过程，或者可以认为是无条件内联进去了[2]。<br />
由于Unsafe类不是提供给用户程序调用的类（Unsafe.getUnsafe（）的代码中限制了只有<br />
启动类加载器（Bootstrap ClassLoader）加载的Class才能访问它），因此，如果不采用反射<br />
手段，我们只能通过其他的Java API来间接使用它，如J.U.C包里面的整数原子类，其中的<br />
compareAndSet（）和getAndIncrement（）等方法都使用了Unsafe类的CAS操作。<br />
我们不妨拿一段在第12章中没有解决的问题代码来看看如何使用CAS操作来避免阻塞同<br />
步，代码如代码清单12-1所示。 我们曾经通过这段20个线程自增10000次的代码来证明<br />
volatile变量不具备原子性，那么如何才能让它具备原子性呢？把“race++”操作或increase（）<br />
方法用同步块包裹起来当然是一个办法，但是如果改成如代码清单13-4所示的代码，那效率<br />
将会提高许多。<br />
代码清单13-4 Atomic的原子自增运算<br />
/**<br />
*Atomic变量自增运算测试<br />
**<br />
@author zzm<br />
*/<br />
public class AtomicTest{<br />
public static AtomicInteger race=new AtomicInteger（0）；<br />
public static void increase（）{<br />
race.incrementAndGet（）；<br />
}p<br />
rivate static final int THREADS_COUNT=20；<br />
public static void main（String[]args）throws Exception{<br />
Thread[]threads=new Thread[THREADS_COUNT]；<br />
for（int i=0；i＜THREADS_COUNT；i++）{<br />
threads[i]=new Thread（new Runnable（）{<br />
@Override<br />
public void run（）{<br />
for（int i=0；i＜10000；i++）{<br />
increase（）；<br />
}}}<br />
）；<br />
threads[i].start（）；<br />
}w<br />
hile（Thread.activeCount（）＞1）<br />
Thread.yield（）；<br />
System.out.println（race）；<br />
}} 运<br />
行结果如下：<br />
200000<br />
使用AtomicInteger代替int后，程序输出了正确的结果，一切都要归功于<br />
incrementAndGet（）方法的原子性。 它的实现其实非常简单，如代码清单13-5所示。<br />
代码清单13-5 incrementAndGet（）方法的JDK源码<br />
/**<br />
*Atomically increment by one the current value.<br />
*@return the updated value<br />
*/<br />
public final int incrementAndGet（）{<br />
for（；）{<br />
int current=get（）；<br />
int next=current+1；<br />
if（compareAndSet（current,next））<br />
return next；<br />
}} i<br />
ncrementAndGet（）方法在一个无限循环中，不断尝试将一个比当前值大1的新值赋给<br />
自己。 如果失败了，那说明在执行“获取-设置”操作的时候值已经有了修改，于是再次循环<br />
进行下一次操作，直到设置成功为止。<br />
尽管CAS看起来很美，但显然这种操作无法涵盖互斥同步的所有使用场景，并且CAS从<br />
语义上来说并不是完美的，存在这样的一个逻辑漏洞：如果一个变量V初次读取的时候是A<br />
值，并且在准备赋值的时候检查到它仍然为A值，那我们就能说它的值没有被其他线程改变<br />
过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认<br />
为它从来没有被改变过。 这个漏洞称为CAS操作的“ABA”问题。 J.U.C包为了解决这个问题，<br />
提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本<br />
来保证CAS的正确性。 不过目前来说这个类比较“鸡肋”，大部分情况下ABA问题不会影响程<br />
序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会比原子类更高效。<br />
3.无同步方案<br />
要保证线程安全，并不是一定就要进行同步，两者没有因果关系。 同步只是保证共享数<br />
据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步<br />
措施去保证正确性，因此会有一些代码天生就是线程安全的，笔者简单地介绍其中的两类。<br />
可重入代码（Reentrant Code）：这种代码也叫做纯代码（Pure Code），可以在代码执<br />
行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回<br />
后，原来的程序不会出现任何错误。 相对线程安全来说，可重入性是更基本的特性，它可以<br />
保证线程安全，即所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都<br />
是可重入的。<br />
可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、 用到<br />
的状态量都由参数中传入、 不调用非可重入的方法等。 我们可以通过一个简单的原则来判断<br />
代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数<br />
据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。<br />
线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码<br />
共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就<br />
可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出<br />
现数据争用的问题。<br />
符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费<br />
者”模式）都会将产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就<br />
是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方<br />
式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程<br />
安全问题。<br />
Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变<br />
的”；如果一个变量要被某个线程独享，Java中就没有类似C++中__declspec（thread）[3]这样<br />
的关键字，不过还是可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。 每一个线<br />
程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以<br />
ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就<br />
是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的<br />
threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。<br />
[1]本例中的数据及图片来源于Brian Goetz为IBM developerWorks撰写的论文：《 Java theory<br />
and practice：More flexible,scalable locking in JDK 5.0》 ，原文地址是：<br />
http://www.ibm.com/developerworks/java/library/j-jtp10264/?S_TACT=105AGX52＆S_CMP=cna-j。<br />
[2]这种被虚拟机特殊处理的方法称为固有函数（Intrinsics），类似的固有函数还有<br />
Math.sin（）等。<br />
[3]在Visual C++中是“__declspec（thread）”关键字，而在GCC中是“__thread”。<br />
13.3 锁优化<br />
高效并发是从JDK 1.5到JDK 1.6的一个重要改进，HotSpot虚拟机开发团队在这个版本上<br />
花费了大量的精力去实现各种锁优化技术，如适应性自旋（Adaptive Spinning）、 锁消除<br />
（Lock Elimination）、 锁粗化（Lock Coarsening）、 轻量级锁（Lightweight Locking）和偏向<br />
锁（Biased Locking）等，这些技术都是为了在线程之间更高效地共享数据，以及解决竞争问<br />
题，从而提高程序的执行效率。<br />
13.3.1 自旋锁与自适应自旋<br />
前面我们讨论互斥同步的时候，提到了互斥同步对性能最大的影响是阻塞的实现，挂起<br />
线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的<br />
压力。 同时，虚拟机的开发团队也注意到在许多应用上，共享数据的锁定状态只会持续很短<br />
的一段时间，为了这段时间去挂起和恢复线程并不值得。 如果物理机器有一个以上的处理<br />
器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程“稍等一<br />
下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。 为了让线程等<br />
待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。<br />
自旋锁在JDK 1.4.2中就已经引入，只不过默认是关闭的，可以使用-XX：+UseSpinning<br />
参数来开启，在JDK 1.6中就已经改为默认开启了。 自旋等待不能代替阻塞，且先不说对处<br />
理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，<br />
因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间<br />
很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性<br />
能上的浪费。 因此，自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然<br />
没有成功获得锁，就应当使用传统的方式去挂起线程了。 自旋次数的默认值是10次，用户可<br />
以使用参数-XX：PreBlockSpin来更改。<br />
在JDK 1.6中引入了自适应的自旋锁。 自适应意味着自旋的时间不再固定了，而是由前<br />
一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 如果在同一个锁对象上，自旋等<br />
待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也很有<br />
可能再次成功，进而它将允许自旋等待持续相对更长的时间，比如100个循环。 另外，如果<br />
对于某个锁，自旋很少成功获得过，那在以后要获取这个锁时将可能省略掉自旋过程，以避<br />
免浪费处理器资源。 有了自适应自旋，随着程序运行和性能监控信息的不断完善，虚拟机对<br />
程序锁的状况预测就会越来越准确，虚拟机就会变得越来越“聪明”了。<br />
13.3.2 锁消除<br />
锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能<br />
存在共享数据竞争的锁进行消除。 锁消除的主要判定依据来源于逃逸分析的数据支持（第11<br />
章已经讲解过逃逸分析技术），如果判断在一段代码中，堆上的所有数据都不会逃逸出去从<br />
而被其他线程访问到，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加<br />
锁自然就无须进行。<br />
也许读者会有疑问，变量是否逃逸，对于虚拟机来说需要使用数据流分析来确定，但是<br />
程序员自己应该是很清楚的，怎么会在明知道不存在数据争用的情况下要求同步呢？答案是<br />
有许多同步措施并不是程序员自己加入的，同步的代码在Java程序中的普遍程度也许超过了<br />
大部分读者的想象。 我们来看看代码清单13-6中的例子，这段非常简单的代码仅仅是输出3<br />
个字符串相加的结果，无论是源码字面上还是程序语义上都没有同步。<br />
代码清单13-6 一段看起来没有同步的代码<br />
public String concatString（String s1，String s2，String s3）{<br />
return s1+s2+s3；<br />
} 我<br />
们也知道，由于String是一个不可变的类，对字符串的连接操作总是通过生成新的<br />
String对象来进行的，因此Javac编译器会对String连接做自动优化。 在JDK 1.5之前，会转化<br />
为StringBuffer对象的连续append（）操作，在JDK 1.5及以后的版本中，会转化为<br />
StringBuilder对象的连续append（）操作，即代码清单13-6中的代码可能会变成代码清单13-7<br />
的样子[1]。<br />
代码清单13-7 Javac转化后的字符串连接操作<br />
public String concatString（String s1，String s2，String s3）{<br />
StringBuffer sb=new StringBuffer（）；<br />
sb.append（s1）；<br />
sb.append（s2）；<br />
sb.append（s3）；<br />
return sb.toString（）；<br />
} 现<br />
在大家还认为这段代码没有涉及同步吗？每个StringBuffer.append（）方法中都有一个<br />
同步块，锁就是sb对象。 虚拟机观察变量sb，很快就会发现它的动态作用域被限制在<br />
concatString（）方法内部。 也就是说，sb的所有引用永远不会“逃逸”到concatString（）方法<br />
之外，其他线程无法访问到它，因此，虽然这里有锁，但是可以被安全地消除掉，在即时编<br />
译之后，这段代码就会忽略掉所有的同步而直接执行了。<br />
[1]客观地说，既然谈到锁消除与逃逸分析，那虚拟机就不可能是JDK 1.5之前的版本，实际<br />
上会转化为非线程安全的StringBuilder来完成字符串拼接，并不会加锁，但这也不影响笔者<br />
用这个例子证明Java对象中同步的普遍性。<br />
13.3.3 锁粗化<br />
原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小——只在<br />
共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如<br />
果存在锁竞争，那等待锁的线程也能尽快拿到锁。<br />
大部分情况下，上面的原则都是正确的，但是如果一系列的连续操作都对同一个对象反<br />
复加锁和解锁，甚至加锁操作是出现在循环体中的，那即使没有线程竞争，频繁地进行互斥<br />
同步操作也会导致不必要的性能损耗。<br />
代码清单13-7中连续的append（）方法就属于这类情况。 如果虚拟机探测到有这样一串<br />
零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外<br />
部，以代码清单13-7为例，就是扩展到第一个append（）操作之前直至最后一个append（）<br />
操作之后，这样只需要加锁一次就可以了。<br />
13.3.4 轻量级锁<br />
轻量级锁是JDK 1.6之中加入的新型锁机制，它名字中的“轻量级”是相对于使用操作系统<br />
互斥量来实现的传统锁而言的，因此传统的锁机制就称为“重量级”锁。 首先需要强调一点的<br />
是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传<br />
统的重量级锁使用操作系统互斥量产生的性能消耗。<br />
要理解轻量级锁，以及后面会讲到的偏向锁的原理和运作过程，必须从HotSpot虚拟机<br />
的对象（对象头部分）的内存布局开始介绍。 HotSpot虚拟机的对象头（Object Header）分为<br />
两部分信息，第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、 GC分代<br />
年龄（Generational GC Age）等，这部分数据的长度在32位和64位的虚拟机中分别为32bit和<br />
64bit，官方称它为“Mark Word”，它是实现轻量级锁和偏向锁的关键。 另外一部分用于存储<br />
指向方法区对象类型数据的指针，如果是数组对象的话，还会有一个额外的部分用于存储数<br />
组长度。<br />
对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效<br />
率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它<br />
会根据对象的状态复用自己的存储空间。 例如，在32位的HotSpot虚拟机中对象未被锁定的<br />
状态下，Mark Word的32bit空间中的25bit用于存储对象哈希码（HashCode），4bit用于存储<br />
对象分代年龄，2bit用于存储锁标志位，1bit固定为0，在其他状态（轻量级锁定、 重量级锁<br />
定、 GC标记、 可偏向）下对象的存储内容见表13-1。<br />
简单地介绍了对象的内存布局后，我们把话题返回到轻量级锁的执行过程上。 在代码进<br />
入同步块的时候，如果此同步对象没有被锁定（锁标志位为“01”状态），虚拟机首先将在当<br />
前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark<br />
Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word），这时候线<br />
程堆栈与对象头的状态如图13-3所示。<br />
然后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。<br />
如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标<br />
志位（Mark Word的最后2bit）将转变为“00”，即表示此对象处于轻量级锁定状态，这时候线<br />
程堆栈与对象头的状态如图13-4所示。<br />
图 13-3 轻量级锁CAS操作之前堆栈与对象的状态[1]<br />
图 13-4 轻量级锁CAS操作之后堆栈与对象的状态<br />
如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈<br />
帧，如果只说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否<br />
则说明这个锁对象已经被其他线程抢占了。 如果有两条以上的线程争用同一个锁，那轻量级<br />
锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指<br />
向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。<br />
上面描述的是轻量级锁的加锁过程，它的解锁过程也是通过CAS操作来进行的，如果对<br />
象的Mark Word仍然指向着线程的锁记录，那就用CAS操作把对象当前的Mark Word和线程中<br />
复制的Displaced Mark Word替换回来，如果替换成功，整个同步过程就完成了。 如果替换失<br />
败，说明有其他线程尝试过获取该锁，那就要在释放锁的同时，唤醒被挂起的线程。<br />
轻量级锁能提升程序同步性能的依据是“对于绝大部分的锁，在整个同步周期内都是不<br />
存在竞争的”，这是一个经验数据。 如果没有竞争，轻量级锁使用CAS操作避免了使用互斥<br />
量的开销，但如果存在锁竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞<br />
争的情况下，轻量级锁会比传统的重量级锁更慢。<br />
[1]图13-3和图13-4来源于HotSpot虚拟机的一位Senior Staff Engineer——Paul Hohensee所写的<br />
PPT“The Hotspot Java Virtual Machine”。<br />
13.3.5 偏向锁<br />
偏向锁也是JDK 1.6中引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步<br />
原语，进一步提高程序的运行性能。 如果说轻量级锁是在无竞争的情况下使用CAS操作去消<br />
除同步使用的互斥量，那偏向锁就是在无竞争的情况下把整个同步都消除掉，连CAS操作都<br />
不做了。<br />
偏向锁的“偏”，就是偏心的“偏”、 偏袒的“偏”，它的意思是这个锁会偏向于第一个获得<br />
它的线程，如果在接下来的执行过程中，该锁没有被其他的线程获取，则持有偏向锁的线程<br />
将永远不需要再进行同步。<br />
如果读者读懂了前面轻量级锁中关于对象头Mark Word与线程之间的操作过程，那偏向<br />
锁的原理理解起来就会很简单。 假设当前虚拟机启用了偏向锁（启用参数-XX：<br />
+UseBiasedLocking，这是JDK 1.6的默认值），那么，当锁对象第一次被线程获取的时候，<br />
虚拟机将会把对象头中的标志位设为“01”，即偏向模式。 同时使用CAS操作把获取到这个锁<br />
的线程的ID记录在对象的Mark Word之中，如果CAS操作成功，持有偏向锁的线程以后每次<br />
进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作（例如Locking、 Unlocking<br />
及对Mark Word的Update等）。<br />
当有另外一个线程去尝试获取这个锁时，偏向模式就宣告结束。 根据锁对象目前是否处<br />
于被锁定的状态，撤销偏向（Revoke Bias）后恢复到未锁定（标志位为“01”）或轻量级锁定<br />
（标志位为“00”）的状态，后续的同步操作就如上面介绍的轻量级锁那样执行。 偏向锁、 轻<br />
量级锁的状态转化及对象Mark Word的关系如图13-5所示。<br />
图 13-5 偏向锁、 轻量级锁的状态转化及对象Mark Word的关系<br />
偏向锁可以提高带有同步但无竞争的程序性能。 它同样是一个带有效益权衡（Trade<br />
Off）性质的优化，也就是说，它并不一定总是对程序运行有利，如果程序中大多数的锁总<br />
是被多个不同的线程访问，那偏向模式就是多余的。 在具体问题具体分析的前提下，有时候<br />
使用参数-XX：-UseBiasedLocking来禁止偏向锁优化反而可以提升性能。<br />
13.4 本章小结<br />
本章介绍了线程安全所涉及的概念和分类、 同步实现的方式及虚拟机的底层运作原理，<br />
并且介绍了虚拟机为了实现高效并发所采取的一系列锁优化措施。<br />
许多资深的程序员都说过，能够写出高伸缩性的并发程序是一门艺术，而了解并发在系<br />
统底层是如何实现的，则是掌握这门艺术的前提条件，也是成长为高级程序员的必备知识之<br />
一。<br />
附录<br />
附录A 编译Windows版的OpenJDK<br />
附录B 虚拟机字节码指令表<br />
附录C HotSpot虚拟机主要参数表<br />
附录D 对象查询语言（OQL）简介<br />
附录E JDK历史版本轨迹<br />
附录A 编译Windows版的OpenJDK<br />
A.1 获取JDK源码<br />
首先确定要使用的JDK版本，OpenJDK 6和OpenJDK 7都是开源的，源码都可以在它们的<br />
主页（http://openjdk.java.net/）上找到，OpenJDK 6的源码其实是从OpenJDK 7的某个基线中<br />
引出的，然后剥离掉JDK 1.7相关的代码，从而得到一份可以通过TCK 6的JDK 1.6实现，因<br />
此直接编译OpenJDK 7会更加“原汁原味”一些，其实这两个版本的编译过程差异并不大。<br />
获取源码有两种方式。 一种是通过Mercurial代码版本管理工具从Repository中直接取得<br />
源码（Repository地址：http://hg.openjdk.java.net/jdk7/jdk7），这是最直接的方式，从版本管<br />
理中看变更轨迹比看什么Release Note都来得实在，不过坏处自然是太麻烦了一些，尤其是<br />
Mercurial远不如SVN、 ClearCase或CVS之类的版本控制工具那样普及。 另一种就是直接下载<br />
官方打包好的源码包了，可以从Source Releases页面（地址：<br />
http://download.java.net/openjdk/jdk7/）取得打包好的源码，一般来说大概一个月会更新一<br />
次，虽然不够及时，但的确方便了许多。 笔者下载的是OpenJDK 7 Early Access Source Build<br />
b121版，2010年12月9日发布的，大概81.7MB，解压后约308MB。<br />
A.2 系统需求<br />
如果可能，笔者建议尽量在Linux或Solaris上构建OpenJDK，这要比在Windows平台上轻<br />
松许多，而且网络上能找到的资料绝大部分都是在Linux上编译的。 如果一定要在Windows平<br />
台上编译，建议读者认真阅读一下源码中的README-builds.html文档（无论在OpenJDK网站<br />
上还是在下载的源码包里面都有这份文档），因为编译过程中需要注意的细节非常多。 虽然<br />
不至于像文档上所描述的“Building the source code for the JDK requires a high level of technical<br />
expertise.Sun provides the source code primarily for technical experts who want to conduct<br />
research（编译JDK需要很高的专业技术，Sun提供JDK源码是为了技术专家进行研究之<br />
用）”那么夸张，但是如果读者是第一次编译，那在上面耗费一整天乃至更多的时间都很正<br />
常。<br />
笔者在本次实战中演示的是在32位Windows 7平台下编译x86版的OpenJDK（也就是32位<br />
的JDK），如果需要编译x64版，那毫无疑问也需要一个64位的操作系统。 另外，编译涉及<br />
的所有文件都必须存放在NTFS格式的文件系统中，因为FAT32格式无法支持大小写敏感的<br />
文件名。 在官方文档上写着：编译至少需要512MB的内存和600MB的磁盘空间。 512MB的内<br />
存基本上也可以凑合使用，不过600MB的磁盘空间仅仅是指存放OpenJDK源码和相关依赖项<br />
的空间，要完成编译，600MB肯定是无论如何都不够的，这次实战中所下载的工具、 依赖<br />
项、 源码，全部安装、 解压完成最少（最少是指只下载C++编译器，不下载VS的IDE）需要<br />
超过1GB的空间。<br />
对系统的最后一点要求就是所有的文件，包括源码和依赖项目，都不要放在包含中文或<br />
空格的目录里面，这样做不是一定不可以，只是这样会为后续建立CYGWIN环境带来很多额<br />
外的工作，这是由于Linux和Windows的磁盘路径差别所导致的，我们也没有必要给自己找麻<br />
烦。<br />
A.3 构建编译环境<br />
准备编译环境的第一步是去安装一个CYGWIN[1]。 这是一个在Windows平台下模拟Linux<br />
运行环境的软件，提供了一系列的Linux命令支持。 需要CYGWIN的原因是在编译中要使用<br />
GNU Make来执行Makefile文件（C/C++程序员肯定很熟悉，如果只使用Java，那把这个东西<br />
当做C++版本的ANT看待就可以了）。 安装CYGWIN时不能直接默认安装，因为表A-1中所<br />
示的工具都不会进行默认安装，但又是编译过程中需要的，因此要在图A-1的安装界面中进<br />
行手工选择。<br />
CYGWIN安装时的定制包选择界面如图A-1所示：<br />
图 A-1 CYGWIN安装界面<br />
建立编译环境的第二步是安装编译器。 JDK中最核心的代码（Java虚拟机及JDK中Native<br />
方法的实现等）是使用C++语言及少量的C语言编写的，官方文档中说他们的内部开发环境<br />
是在Microsoft Visual Studio C++2003（VS2003）中进行编译，同时也在Microsoft Visual Studio<br />
C++2010（VS2010）中测试过，所以最好只选择这两个编译器之一进行编译。 如果选择<br />
VS2010，那么在编译器之中已经包含了Windows SDK v 7.0a，否则可能还要自己去下载这个<br />
SDK，并且更新PlatformSDK目录。 由于Visual Studio 2010的IDE是收费的，所以仅仅下载了<br />
VS2010 Express中提取出来的C++编译器，这部分是免费的，但单独安装好编译器比较麻<br />
烦。 建议读者选择使用整套Visual Studio C++2010或Visual Studio C++2010 Express版进行编<br />
译。<br />
需要特别注意的一点是，CYGWIN和VS2010安装之后都会在操作系统的PATH环境变量<br />
中写入自己的bin目录路径，必须检查并保证VS2010的bin目录一定要在CYGWIN的bin目录之<br />
前，因为这两个软件的bin目录之中各自都有个连接器“link.exe”，但是只有VS2010中的连接<br />
器可以完成OpenJDK的编译。<br />
准备JDK编译环境的第三步就是下载一个已经编译好了的JDK。 这听起来也许有点滑稽<br />
——要用鸡蛋孵小鸡还真得必须先养一只母鸡呀？但仔细想想其实这个步骤很合理：因为<br />
JDK包含的各个部分（Hotspot、 JDK API、 JAXWS、 JAXP……）有的是使用C++编写的，而<br />
更多的代码则是使用Java自身实现的，因此编译这些Java代码需要用到一个可用的JDK，官<br />
方称这个JDK为“Bootstrap JDK”。 而编译OpenJDK 7的话，Bootstrap JDK必须使用JDK6<br />
Update 14或之后的版本，笔者选用的是JDK6 Update 21。<br />
最后一个步骤是下载一个Apache ANT,JDK中Java代码部分都是使用ANT脚本进行编译<br />
的，ANT版本要求在1.6.5以上，这部分是Java的基础知识，对本书的读者来说应该没有难<br />
度，笔者不再详述。<br />
[1]CYGWIN下载地址：http://www.cygwin.com/。<br />
A.4 准备依赖项<br />
前面说过，OpenJDK中开放的源码并没有达到100%，还有极少量的无法开源的产权代<br />
码存在。 OpenJDK承诺日后将逐步使用开源实现来替换掉这部分产权代码，但至少在今天，<br />
编译JDK还需要这部分闭源包，官方称之为“JDK Plug”[1]，它们从前面的Source Releases页面<br />
就可以下载到。 在Windows平台的JDK Plug是以Jar包的形式提供的，通过下面这条命令可以<br />
安装它：<br />
java-jar jdk-7-ea-plug-b121-windows-i586-09_dec_2010.jar<br />
运行后将会显示如图A-2所示的协议，点击ACCEPT接受协议，然后把Plug安装到指定目<br />
录即可。 安装完毕后建立一个环境变量“ALT_BINARY_PLUGS_PATH”，变量值为此JDK<br />
Plug的安装路径，后面编译程序时需要用到它。<br />
除了要用到JDK Plug外，编译时还需要引用JDK的运行时包，这个是编译JDK中用Java代<br />
码编写的那部分所需要的，如果仅仅是想编译一个HotSpot虚拟机的话则可以不用。 官方文<br />
档把这部分称为“Optional Import JDK”，可以直接使用前面Bootstrap JDK的运行时包，我们需<br />
要建立一个名为“ALT_JDK_IMPORT_PATH”的环境变量指向JDK的安装目录。<br />
图 A-2 JDK Plug安装协议<br />
然后是安装一个大于2.3版的FreeType[2]，这是一个免费的字体渲染库，JDK的Swing部分<br />
和JConsole这类工具要使用到它。 安装好后建立两个环境变<br />
量“ALT_FREETYPE_LIB_PATH”和“ALT_FREETYPE_HEADERS_PATH”，分别指向FreeType<br />
安装目录下的bin目录和include目录。 另外还有一点官方文档没有提到但必须要做的事情是把<br />
FreeType的bin目录加入到PATH环境变量中。<br />
然后下载Microsoft DirectX 9.0 SDK（Summer 2004），安装后大约有298MB，在微软官<br />
方网站上搜索一下就可以找到下载地址，它是免费的。 安装后建立环境变<br />
量“ALT_DXSDK_PATH”指向DirectX 9.0 SDK的安装目录。<br />
然后去寻找一个名为“MSVCR100.DLL”的动态链接库，如果读者在前面安装了全套的<br />
Visual Studio 2010，那这个文件在本机就能找到，否则上网搜索一下也能找到单独的下载地<br />
址，大概有744KB。 建立环境变量“ALT_MSVCRNN_DLL_PATH”指向这个文件所在的目录。<br />
如果读者选择的是VS2003，这个文件名应当为“MSVCR73.DLL”，应该在很多软件中都包含<br />
有这个文件，如果找不到的话，前面下载的“Bootstrap JDK”的bin目录中应该也有一个，直接<br />
拿来用吧。<br />
[1]在2011年，JDK plug已经不再需要了，但在笔者写本次实战时使用的2010年12月9日发布<br />
的OpenJDK b121版还是需要这些JDK plug。<br />
[2]FreeType主页：http://www.freetype.org/。<br />
A.5 进行编译<br />
现在需要下载的编译环境和依赖项目都准备齐全了，最后我们还需要对系统做一些设置<br />
以便编译能够顺利通过。<br />
首先执行VS2010中的VCVARS32.BAT，这个批处理文件的目的主要是设置INCLUDE、<br />
LIB和PATH这几个环境变量，如果和笔者一样只是下载了编译器的话则需要手工设置它们，<br />
各个环境变量的设置值可以参考下面给出的代码清单A-1中的内容。 批处理运行完之后建<br />
立“ALT_COMPILER_PATH”环境变量让Makefile知道在哪里可以找到编译器。<br />
再建立“ALT_BOOTDIR”和“ALT_JDK_IMPORT_PATH”两个环境变量指向前面提到的<br />
JDK 1.6的安装目录。 建立“ANT_HOME”指向Apache ANT的安装目录。 建立的环境变量很<br />
多，为了避免遗漏，笔者写了一个批处理文件以供读者参考，如代码清单A-1所示。<br />
代码清单A-1 环境变量设置<br />
SET ALT_BOOTDIR=D：/_DevSpace/JDK 1.6.0_21<br />
SET ALT_BINARY_PLUGS_PATH=D：/jdkBuild/jdk7plug/openjdk-binary-plugs<br />
SET ALT_JDK_IMPORT_PATH=D：/_DevSpace/JDK 1.6.0_21<br />
SET ANT_HOME=D：/jdkBuild/apache-ant-1.7.0<br />
SET ALT_MSVCRNN_DLL_PATH=D：/jdkBuild/msvcr100<br />
SET ALT_DXSDK_PATH=D：/jdkBuild/msdxsdk<br />
SET ALT_COMPILER_PATH=D：/jdkBuild/vcpp2010.x86/bin<br />
SET ALT_FREETYPE_HEADERS_PATH=D：/jdkBuild/freetype-2.3.5-1-bin/include<br />
SET ALT_FREETYPE_LIB_PATH=D：/jdkBuild/freetype-2.3.5-1-bin/bin<br />
SET INCLUDE=D：/jdkBuild/vcpp2010.x86/include；D：/jdkBuild/vcpp2010.x86/sdk/Include；%INCLUDE%<br />
SET LIB=D：/jdkBuild/vcpp2010.x86/lib；D：/jdkBuild/vcpp2010.x86/sdk/Lib；%LIB%<br />
SET LIBPATH=D：/jdkBuild/vcpp2010.x86/lib；%LIB%<br />
SET PATH=D：/jdkBuild/vcpp2010.x86/bin；D：/jdkBuild/vcpp2010.x86/dll/x86；D：/Software/OpenSource/cygwin/bin；%ALT_FREETYPE_LIB_PATH%；%PATH%<br />
最后还需要进行两项调整，虽然，官方文档没有说明这两项，但是必须要做完才能保证<br />
编译过程的顺利通过：一项是取消环境变量JAVA_HOME，这点很简单；另外一项是尽量在<br />
英文的操作系统上编译，如果不能在英文的系统上编译就把系统的文字格式调整为“英语<br />
（美国）”，在控制面板-区域和语言选项的第一个页签中可以设置。 如果这个设置还不能更<br />
改就建立一个“BUILD_CORBA”的环境变量，将值设置为false，取消编译CORBA部分，否则<br />
Java IDL（idlj.exe）为*.idl文件生成CORBA适配器代码的时候会产生中文注释，而这些中文<br />
注释会因为字符集的问题而导致编译失败。<br />
完成了上述的准备工作之后，我们终于可以开始编译了。 进入控制台（Cmd.exe）后运<br />
行刚才准备好的设置环境变量的批处理文件，然后输入bash进入Bourne Again Shell环境（sh<br />
或ksh也可以）。 如果JDK的安装源码中存在“jdk_generic_profile.sh”这个Shell脚本，先执行<br />
它，笔者下载的OpenJDK 7 B121版没有这个文件了，所以直接输入make sanity来检查我们前<br />
面所做的设置是否全部正确。 如果一切顺利，那么几秒钟之后会有类似代码清单A-2所示的<br />
输出。<br />
代码清单A-2 make sanity检查<br />
D：\jdkBuild\openjdk7＞bash<br />
bash-3.2$make sanity<br />
cygwin warning：<br />
MS-DOS style path detected：C：/Windows/system32/wscript.exe<br />
Preferred POSIX equivalent is：/cygdrive/c/Windows/system32/wscript.exe<br />
CYGWIN environment variable option"nodosfilewarning"turns off this warning.<br />
Consult the user's guide for more details about POSIX paths：<br />
http://cygwin.com/cygwin-ug-net/using.html#using-pathnames<br />
（cd./jdk/make＆＆\<br />
……因篇幅关系，中间省略了大量的输出内容……<br />
OpenJDK-specific settings：<br />
FREETYPE_HEADERS_PATH=D：/jdkBuild/freetype-2.3.5-1-bin/include<br />
ALT_FREETYPE_HEADERS_PATH=D：/jdkBuild/freetype-2.3.5-1-bin/include<br />
FREETYPE_LIB_PATH=D：/jdkBuild/freetype-2.3.5-1-bin/bin<br />
ALT_FREETYPE_LIB_PATH=D：/jdkBuild/freetype-2.3.5-1-bin/bin<br />
OPENJDK Import Binary Plug Settings：<br />
IMPORT_BINARY_PLUGS=true<br />
BINARY_PLUGS_JARFILE=D：/jdkBuild/jdk7plug/openjdk-binary-plugs/jre/lib/rt-closed.jar<br />
ALT_BINARY_PLUGS_JARFILE=<br />
BINARY_PLUGS_PATH=D：/jdkBuild/jdk7plug/openjdk-binary-plugs<br />
ALT_BINARY_PLUGS_PATH=D：/jdkBuild/jdk7plug/openjdk-binary-plugs<br />
BUILD_BINARY_PLUGS_PATH=J：/re/jdk/1.7.0/promoted/latest/openjdk/binaryplugs<br />
ALT_BUILD_BINARY_PLUGS_PATH=<br />
PLUG_LIBRARY_NAMES=<br />
Previous JDK Settings：<br />
PREVIOUS_RELEASE_PATH=USING-PREVIOUS_RELEASE_IMAGE<br />
ALT_PREVIOUS_RELEASE_PATH=<br />
PREVIOUS_JDK_VERSION=1.6.0<br />
ALT_PREVIOUS_JDK_VERSION=<br />
PREVIOUS_JDK_FILE=<br />
ALT_PREVIOUS_JDK_FILE=<br />
PREVIOUS_JRE_FILE=<br />
ALT_PREVIOUS_JRE_FILE=<br />
PREVIOUS_RELEASE_IMAGE=D：/_DevSpace/JDK 1.6.0_21<br />
ALT_PREVIOUS_RELEASE_IMAGE=<br />
Sanity check passed.<br />
Makefile的Sanity检查过程输出了编译所需的所有环境变量，如果看到“Sanity check<br />
passed.”，说明检查过程通过了，可以输入“make”执行整个Makefile，笔者使用Core i5/4GB<br />
RAM的机器编译整个JDK大概需要半个多小时。 如果失败则需要根据系统输出的失败原因，<br />
回头再检查一下对应的设置。 并且最好在下一次编译之前先执行“make clean”来清理掉上次<br />
编译遗留的文件。<br />
编译完成之后，打开OpenJDK源码下的build目录，看看是不是已经有一个编译好的JDK<br />
在那里等着了？执行一下“java-version”，看到以自己机器命名的JDK了吧，很有成就感吧！<br />
附录B 虚拟机字节码指令表</p>

<p>附录C HotSpot虚拟机主要参数表<br />
本参数表以JDK 1.6为基础编写，JDK 1.6的HotSpot虚拟机有很多非稳定参数（Unstable<br />
Options，即以-XX：开头的参数，JDK 1.6的虚拟机中大概有660多个），使用-XX：<br />
+PrintFlagsFinal参数可以输出所有参数的名称及默认值（默认不包括Diagnostic和Experimental<br />
的参数，如果需要，可以配合-XX：+UnlockDiagnosticVMOptions/-XX：<br />
+UnlockExperimentalVMOptions一起使用），下面的各个表格只包含了其中最常用的（或在本<br />
书中介绍到的）部分。 参数使用的方式有如下3种：<br />
-XX：+＜option＞开启option参数。<br />
-XX：-＜option＞关闭option参数。<br />
-XX：＜option＞=＜value＞将option参数的值设置为value。<br />
C.1 内存管理参数</p>

<p>C.2 即时编译参数<br />
C.3 类型加载参数<br />
C.4 多线程相关参数<br />
C.5 性能参数<br />
C.6 调试参数<br />
附录D 对象查询语言（OQL）简介[1]<br />
D.1 SELECT子句<br />
SELECT子句用于确定查询语句需要从堆转储快照中选择什么内容。 如果需要显示堆转<br />
储快照中的对象，并且浏览这些对象的引用关系，可以使用“*”，这与传统SQL语句中的习惯<br />
是一致的，如：<br />
SELECT * FROM java.lang.String<br />
1.选择特定的显示列<br />
查询也可以选择特定的需要显示的字段，如：<br />
SELECT toString（s），s.count,s.value FROM java.lang.String s<br />
查询可以用“@”符号来使用Java对象的内存属性访问器。 MAT提供了一系列的内置函数<br />
来获取与分析相关的信息，如：<br />
SELECT toString（s），s.@usedHeapSize,s.@retainedHeapSize FROM java.lang.String s<br />
关于对象属性访问器的具体内容，可以参见下文的“属性访问器”。<br />
2.使用列别名<br />
可以使用AS关键字来对选择的列进行命名，如：<br />
SELECT toString（s）AS Value，<br />
s.@usedHeapSize AS"Shallow Size"，<br />
s.@retainedHeapSize AS"Retained Size"<br />
FROM java.lang.String s<br />
可以使用“AS RETAINED SET”关键字来获得与选择对象相关联的对象集合，如：<br />
SELECT AS RETAINED SET * FROM java.lang.String<br />
3.拼合成为一个对象列表选择项目<br />
可以使用“OBJECTS”关键字把SELECT子句中查找出来的数据项目转变为对象，如：<br />
SELECT OBJECTS dominators（s）FROM java.lang.String s<br />
上面例子中，函数“dominators（）”将会返回一个对象数组，因此，如果没<br />
有“OBJECTS”关键字，上面的查询将返回一组二维的对象数组的列表。 通过使用关键<br />
字“OBJECTS”，我们迫使OQL把查询结果缩减为一维的对象列表。<br />
4.排除重复对象<br />
使用“DISTINCT”关键字可以排除结果集中的重复对象，如：<br />
SELECT DISTINCT classof（s）FROM java.lang.String s<br />
上面的例子中，函数“classof（）”的作用是返回对象所属的Java类，当然，所有字符串<br />
对象的所属类都是java.lang.String，因此，如果上面的查询中没有加入DISTINCT关键字，查<br />
询结果就会返回与快照中的字符串数量一样多的行记录，并且每行记录的内容都是<br />
java.lang.String类型。<br />
[1]本附录翻译自Eclipse Memory Analyzer Tool（MAT,Eclipse出品的内存分析工具）的OQL帮<br />
助文档。<br />
D.2 FROM子句<br />
1.FROM子句指定需要查询的类<br />
OQL查询需要在FROM子句定义的查询范围上进行操作。 FROM子句可以接受的查询范<br />
围描述包括下列几种方式：<br />
1）通过类名进行查询，如：<br />
SELECT * FROM java.lang.String<br />
2）通过正则表达式匹配一组类名进行查询，如：<br />
SELECT * FROM"java\.lang\..*"<br />
3）通过类对象在堆转储快照中的地址进行查询，如：<br />
SELECT * FROM 0xe14a100<br />
4）通过对象在堆转储快照中的ID进行查询，如：<br />
SELECT * FROM 3022<br />
5）在子查询中的结果集中进行查询，如：<br />
SELECT * FROM（SELECT * FROM java.lang.Class c WHERE c implements org.eclipse.mat.snapshot.model.IClass）<br />
上面的查询返回堆转储快照中所有实现了“org.eclipse.mat.snapshot.model.IClass”接口的<br />
类。 下面的这句查询使用属性访问器达到了同样的效果，它直接调用了ISnapshot对象的方<br />
法：<br />
SELECT * FROM $snapshot.getClasses（）<br />
2.包含子类<br />
使用“INSTANCEOF”关键字把指定类的子类列入查询结果集之中，如：<br />
SELECT * FROM INSTANCEOF java.lang.ref.Reference<br />
这个查询的结果集中将会包含WeakReference、 SoftReference和PhantomReference类型的对<br />
象，因为它们都继承自java.lang.ref.Reference。 下面这句查询也有相同的结果：<br />
SELECT * FROM $snapshot.getClassesByName（"java.lang.ref.Reference"，true）<br />
3.禁止查询类实例<br />
在FROM子句中使用“OBJECTS”关键字可以禁止OQL把查询的范围解释为对象实例，<br />
如：<br />
SELECT * FROM OBJECTS java.lang.String<br />
这个查询的结果不是返回快照中所有的字符串，而是只有一个对象，也就是<br />
java.lang.String类对应的Class对象。<br />
D.3 WHERE子句<br />
1.＞=、 ＜=、 ＞、 ＜、 [NOT]LIKE，[NOT]IN（关系操作）<br />
WHERE子句用于指定搜索的条件，即从查询结果中删除不需要的数据，如：<br />
SELECT * FROM java.lang.String s WHERE s.count＞=100<br />
SELECT * FROM java.lang.String s WHERE toString（s）LIKE".*day"<br />
SELECT * FROM java.lang.String s WHERE s.value NOT IN dominators（s）<br />
2.=、 ！=（等于操作）<br />
SELECT * FROM java.lang.String s WHERE toString（s）="monday"<br />
3.AND（条件“与”操作）<br />
SELECT * FROM java.lang.String s WHERE s.count＞100 AND s.@retainedHeapSize＞s.@usedHeapSize<br />
4.OR（条件“或”操作）<br />
条件“或”操作可以应用于表达式、 常量文本和子查询之中，如：<br />
SELECT * FROM java.lang.String s WHERE s.count＞1000 OR s.value.@length＞1000<br />
5.文字表达式<br />
文字表达式包括了布尔值、 字符串、 整型、 长整型和null，如：<br />
SELECT * FROM java.lang.String s<br />
WHERE（s.count＞1000）=true<br />
WHERE toString（s）="monday"<br />
WHERE dominators（s）.size（）=0<br />
WHERE s.@retainedHeapSize＞1024L<br />
WHERE s.@GCRootInfo！=null<br />
D.4 属性访问器<br />
1.访问堆转储快照中对象的字段<br />
对象的内存属性可以通过传统的“点表示法”进行访问，格式为：<br />
[＜alias＞.]＜field＞.＜field＞.＜field＞……<br />
2.访问Java Bean属性<br />
格式为：<br />
[＜alias＞.]@＜attribute＞……<br />
使用@符号，OQL可以访问底层Java对象的内存属性。 下表列出了一些常用的Java属<br />
性。<br />
3.调用OQL Java方法<br />
格式为：<br />
[＜alias＞.]@＜方法＞（[＜表达式＞，＜表达式＞]）……<br />
加“（）”将会令MAT解释为一个OQL Java方法调用。 这个方法的调用是通过反射执行<br />
的。 常见的OQL Java方法如下：<br />
4.OQL的内建函数<br />
格式为：<br />
＜function＞（＜parameter＞）<br />
D.5 OQL语言的BNF范式</p>

<p>附录E JDK历史版本轨迹<br />
大部分的JDK历史版本（JDK 1.1.6之后的版本），以及JDK所附带的各种工具的历史版<br />
本，都可以从Oracle公司的网站[1]上下载到。</p>

<p>[1]下载页面地址：http://www.oracle.com/technetwork/java/archive-139210.html。</p>
