<h1><a href="https://www.cnblogs.com/iloverain/p/8809950.html" id="cb_post_title_url">hadoop HDFS常用文件操作命令</a></h1>

<h2>命令基本格式:</h2>

<p>hadoop fs -cmd &lt; args &gt;</p>

<h2>1. ls</h2>

<p>列出hdfs文件系统根目录下的目录和文件</p>

<p>hadoop fs&nbsp;-ls&nbsp;&nbsp;/dir<br />
hadoop fs&nbsp;-ls&nbsp;-R&nbsp;/dir&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--列出hdfs文件系统所有的目录和文件　</p>

<h2>2.put</h2>

<pre>
hadoop fs -put   <strong>&lt;local file&gt;</strong>  &lt;hdfs file&gt;      --hdfs file的父目录一定要存在，否则命令不会执行</pre>

<p><img alt="" src="https://images2018.cnblogs.com/blog/834385/201804/834385-20180412191041342-285100391.png" /></p>

<pre>
hadoop fs -put &lt;local file or dir&gt; &lt;hdfs dir&gt;    --hdfs dir 一定要存在，否则命令不会执行</pre>

<pre>
hadoop fs -put - &lt;hdfs file&gt;  --从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行</pre>

<h2>3.get</h2>

<pre>
hadoop fs -get &lt;hdfs file&gt; &lt;local file or dir&gt;    --local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地</pre>

<pre>
hadoop fs -get &lt; hdfs file or dir &gt; ... &lt; local  dir &gt;
拷贝多个文件或目录到本地时，本地要为文件夹路径
注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题，</pre>

<h2>4.rm</h2>

<pre>
hadoop fs -rm &lt; hdfs file &gt; ...
hadoop fs -rm -r &lt; hdfs dir&gt;...</pre>

<h3><img alt="" src="https://images2018.cnblogs.com/blog/834385/201804/834385-20180412192629384-416505681.png" /></h3>

<h2>5.mkdir</h2>

<pre>
hadoop fs -mkdir  &lt;hdfs path&gt;  --只能一级一级的建目录，父目录不存在的话使用这个命令会报错</pre>

<pre>
hadoop fs -mkdir -p &lt;hdfs path&gt;   --所创建的目录如果父目录不存在就创建该父目录</pre>

<h2>6.cp</h2>

<pre>
hadoop fs -cp &lt;hdfs file&gt;  &lt;hdfs file&gt;
-- 目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在</pre>

<pre>
hadoop fs -cp &lt;hdfs file or dir&gt; &lt;hdfs dir&gt; --目标文件夹要存在，否则命令不能执行</pre>

<h2>8.mv&nbsp; &nbsp;移动</h2>

<pre>
hadoop fs -mv &lt;hdfs file&gt;  &lt;hdfs file&gt;</pre>

<p>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在</p>

<pre>
hadoop fs -mv  &lt; hdfs file or dir &gt;...  &lt; hdfs dir &gt;
源路径有多个时，目标路径必须为目录，且必须存在。
<strong>注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的</strong></pre>

<h2>9.count&nbsp;</h2>

<pre>
hadoop fs -count &lt;hdfs path&gt;  --统计hdfs对应路径下的目录个数，文件个数，文件总计大小</pre>

<h2>10.text</h2>

<pre>
hadoop fs -text &lt; hdsf file&gt;
将文本文件或某些格式的非文本文件通过文本格式输出</pre>

<h2>11.cat</h2>

<pre>
hadoop fs -cat &lt;hdfs file&gt;/*

hadoop fs -cat /user/hive/back/hs_ods/clientinfo/* &gt;clientinfo.txt
-- 将文件保存到local 文件</pre>

<p>&nbsp;补充知识：</p>

<p>MR的运行依赖数据地址，如果数据地址不存在，则会报错</p>

<h2>&nbsp;12. 在打开的结果中搜索</h2>

<pre>
<strong>hadoop dfs -cat /user/hive/warehouse/fundmarket/* |grep &#39;华夏&#39;</strong></pre>

<p>&nbsp;</p>
