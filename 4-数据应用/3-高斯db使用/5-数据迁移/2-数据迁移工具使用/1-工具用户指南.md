# 迁移软件用户指南

## ddl 校验

进入cfg.ini配置文件，配置"check_ddl":true。 

操作结果： 
Ddl校验不通过，显示结果报红 
报告路径 `./logs/reports_2019-03-26/09h-00m-43s/DDLReport.csv` 
报告内容记录DDL校验情况，以表为单位，生成csv文件

## 数据导出

### 导出流程

进入cfg.ini配置文件，配置如下信息。
```
"flow_type":1,
"export_db":{
"database_type":1,
"db":{
"ip":"",
"username":"",
"password":"",
"port":1888,
"server_name":"DBSVR",
"owner":"dbo"
},
"server":{
"ip":"",
"username":"",
"password":"",
"port":22
}
}

"column_separator":"~##~",
"row_separator":"@#\n#@",
"date_format":"yyyymmddhh24miss",
"timestamp_format":"yyyymmddhh24missff6",
"nls_lang":"utf8",
"data_check_type":1,
"check_obj_exists":true,
"compression_before_translate":false,
"disable_foreign_key":true,
"truncate_after_export_db_data":false,
"check_ddl":true,
"delete_file":false,
"ignore_lost_table":2,
"disable_trigger":true,
"check_ssl_ca":false

"export_threads_per_obj":20,
"export_total_task":10,
"export_allow_max_errors":0,
"export_force":false,
"export_check_row_count":false,
"export_enable_sort":true,
"export_max_rownum":-1,
```
### 数据导出报告

进入cfg.ini配置文件，配置"flow_type":1。

导出报告路径
`/logs/reports_2019-03-25/15h-31m-33s/。`

### 数据导出校验

进入cfg.ini配置文件，配置"export_allow_max_errors":0和"export_check_row_count":false。

导出数据校验结果可以在导出报告中查看

## 数据导入

### 导入流程

进入cfg.ini配置文件，配置如下信息。
```
"flow_type":2,
"export_db":{
"database_type":6,
"db":{
"ip":"",
"username":"",
"password":"",
"port":1888,
"server_name":"",
"owner":""
},
"server":{
"ip":"",
"username":"",
"password":"",
"port":22
}
}

"column_separator":"~##~",
"row_separator":"@#\n#@",
"date_format":"yyyymmddhh24miss",
"timestamp_format":"yyyymmddhh24missff6",
"nls_lang":"utf8",
"data_check_type":1,
"check_obj_exists":true,
"compression_before_translate":false,
"disable_foreign_key":true,
"truncate_after_export_db_data":false,
"check_ddl":true,
"delete_file":false,
"ignore_lost_table":false,
"disable_trigger":true,
"check_ssl_ca":false

"export_threads_per_obj":20,
"export_total_task":10,
"export_allow_max_errors":0,
"export_force":false,
"export_check_row_count":false,
"export_enable_sort":true,
"export_max_rownum":-1,
```

### 数据导入报告

进入cfg.ini配置文件，配置"flow_type":2。

导入报告路径`/logs/reports_2019-03-25/15h-31m-33s/`

### 数据导入校验

进入cfg.ini配置文件，配置"import_check_row_count":false和"import_allow_max_errors":0

导入数据校验结果可以在导出报告中查看

## 注意事项

迁移工具使用注意事项
1.	用户应提前创建好目标库表结构,确保源与目标的字段顺序、表结构一致，字段类型兼容
2.	需保证工具可以用用户配置的ip、端口、用户、密码正确连接数据库
3.	配置中所有密码，需用工具进行加密处理后才可填写至配置文件中，否则会导致验证失败
4.	如果将工具部署在Gauss V3R1版本的数据库服务器上，则执行工具的用户必须是安装Gauss V3R1版本的用户
5.	如果单独配置导入流程，需要用户确认配置的导入文件地址可以在配置导入服务器用户下执行
6.	由于nologging模式不记录undo日志，没法回滚失败记录，所以在使用nologging模式时需要用户自行保证数据正确性
7.	当CompleteReport.csv 日志中校验导入结果为VERIFYERROR时，表示整个数据文件导入失败，请用户检测导入数据库的库名、表名是否正确，或者是否没有将表的状态更改为appendonly(详见9条)
8.	权限 gauss配置的username对应的数据库可以正常访问ALL_TAB_COLUMNS视图中的所有数据，若访问不到，可使用sql
grant all privileges to [userName];
grant DBA to [userName];
为该用户赋权，使用sql
revoke DBA from [userName];
revoke all privileges from [userName];
回收用户权限
9.	如使用nologging模式，需要在V3R1上将表的状态更改为appendonly.
alter table [tableName] appendonly on;
10.	(sybase)若在导出过程中出现not enough user connections available,则按照以下操作执行sp_configure 'number of user connections',500，会提示max memory不足，然后根据提示设置sp_configure 'max memory',200000，再执行sp_configure 'number of user connections',500，就OK；
11.	(sybase)如果sybase数据库出现raise the configuration parameter 'number of open databases'的问题，则执行sp_configure 'number of open databases',500 命令，将同时登陆数据库数量增大
12.	运行程序前先检测源数据库服务器和目标数据库服务器环境
12.1	输入 vi /etc/ssh/sshd_config 命令

12.2	查找是否有MaxSessions和MaxStartups存在，并查看选项后边值。两选项的值必须大于本程序配置文件中import_total_task(对比目标数据库服务器)的值

12.3	如选项前有#号，则将#号去除，如没有该选项则添加该选型至文件空白处
例：MaxSessions 1000 MaxStartups 1000
13.	如果系统为欧拉操作系统则需进行一下操作
-	vim /etc/pam.d/password-auth
-	查看末尾有audit deny=3 even_deny_root unlock_time=300的选项前边是否有#号，没有则添加"#"号并保存文件
例：
#auth required pam_faillock.so preauth audit deny=3 even_deny_root unlock_time=300
-auth sufficient pam_fprintd.so
auth sufficient pam_unix.so nullok try_first_pass
#auth [default=die] pam_faillock.so authfail audit deny=3 even_deny_root unlock_time=300
#auth sufficient pam_faillock.so authsucc audit deny=3 even_deny_root unlock_time=300

-	如出于安全性考虑不做此操作，则程序会出现连接不上服务器的情况
14. [important]进行数据同步之前，请先确保目标库V3R1的配置项EMPTY_STRING_AS_NULL为false，否则无法插入空串
查看及修改步骤：
1）、cd到gauss安装目录，执行vi data/cfg/zengine.ini，查看是否有EMPTY_STRING_AS_NULL配置，若没有该配置，或该配置为true，需进行下一步操作
2）、cd到gauss安装目录，执行python app/bin/zctl.py -t stop
3）、停机后修改步骤1中打开的配置文件，修改或添加 EMPTY_STRING_AS_NULL=false
4）、cd到gauss安装目录，执行python app/bin/zctl.py -t start
15. 如果开启export_append_on模式，则需要在配置为true时将包路径下的ddlResult文件夹删除，以免造成导入文件数据错乱。且此模式只支持一种类型数据库的多次导出，一次导入操作。
16. 本工具依赖各数据库的系统视图，如发现个别表确实有数据但当成空表处理，则可在数据库手动执行一下后，再次尝试数据迁移
oracle: analyze table 表名 compute statistics
mysql: analyze table 表名
V1R3: analyze 模式名.表名
sybase: update statistics low for table 表名


## 附件

### cfg.ini 原文件：

```
{
"flow_type":3,
"export_db":{
"database_type":1,
"db":{
"ip":"",
"username":"",
"password":"",
"port":4100,
"db_name":"",
"server_name":""
}
},

"import_db":{
"database_type":6,
"db":{
"ip":"",
"username":"",
"password":"",
"port":1888
},
"server":{
"ip":"",
"username":"",
"password":"",
"port":22
}
},

"data_path":{
"export_local_path":"",
"export_remote_path":{
"ip":"",
"username":"",
"password":"",
"port":22,
"path":""
},
"import_local_path":"",
"import_remote_path":{
"ip":"",
"username":"",
"password":"",
"port":22,
"path":""
}
},


"option":{

"column_separator":"~~~~~",
"row_separator":"@#\n#@",
"data_check_type":1,
"compression_before_translate":false,
"disable_foreign_key":true,
"check_ddl":true,
"delete_file":true,
"ignore_lost_table":2,
"disable_trigger":true,

"import_nologging":true,
"import_threads_per_obj":10,
"import_total_task":5,
"import_allow_max_errors":0,
"import_force":false,
"import_check_row_count":false,
"truncate_before_import_db_data":true,

"export_total_task":10,
"export_allow_max_errors":0,
"export_force":false,
"export_check_row_count":false,
"export_append_on":false,
"export_max_rownum":-1
}
}
```


### cfg.ini 参数说明

* **flow_type**

* 描述：系统流程类型，可根据需求填写相应数值，1(导出)/2(导入)/3(导出+导入)/4(只校验表结构，不实际导出)
* 必填：是
* 默认值：3


* **export_db**

* 描述：导出数据库/源数据库相关信息
* 必填：系统流程为2时,可不填写结构中的所有信息
* 默认值：无,根据实际情况进行填写
* 注：信息中数字需要填写，否则影响文件格式会出现异常


* **import_db**

* 描述：导入数据库/目标数据库相关信息
* 必填：系统流程为1时,可不填写结构中的所有信息
* 默认值：无,根据实际情况进行填写
* 注：信息中数字需要填写，否则影响文件格式会出现异常


* **database_type**

* 描述：数据库类型，可根据需求填写相应数值，1(sybase)/2(oracle)/3(mysql)/4(Gauss V1R3版本)/5(SQL Server)/6(Gauss V3R1版本)
* 必填：是
* 默认值：导出数据库默认值为1，导入数据库默认值为6


* **db**

* 描述：数据库基本参数，需填写ip(数据库地址)，port(数据库端口)，username(数据库用户名，如是Gauss100数据库填写sys用户后必须在该数据库服务器上运行该程序)，password(数据库密码),server_name(服务名称，如是oracle则必填),db_name(数据库库名，如是mysql和V1R3则必填)
* 必填：是
* 默认值：无,根据实际情况进行填写


* **server**

* 描述：数据库服务器基本参数，需填写ip(服务器)，port(服务器端口，默认为22)，username(服务器对应数据库用户名)，password(服务器密码)
* 必填：当流程类型为2和3时必填
* 默认值：无,根据实际情况进行填写
* 注：如果将工具部署在Gauss100数据库服务器上，则用户名需要用Gauss100安装用户


* **data_path**

* 描述：导入和导出文件存放路径
* 必填：否
* 默认值：无,根据实际情况进行填写


* **export_local_path**

* 描述：导出时导出数据的本地存储地址
* 必填：否
* 默认值：无,根据实际情况进行填写
* 注：当流程类型为1(导出)时，export_local_path可不填写。未填写时，路径为默认路径当前包下的./dataMigration/库名/表名。如果流程类型为3(导入+导出)，则必须配置此路径，并且需要该路径在import.server用户下有权限创建此路径,其他路径均无作用


* **export_remote_path**

* 描述：导出时导出数据的远程存储地址，需填写ip(远程服务器IP)，port(远程服务器端口，默认为22)，username(服务器用户名)，password(服务器密码)，path(导出文件路径)
* 必填：否
* 默认值：无,根据实际情况进行填写
* 注：如同时配置export_local_path和export_remote_path，则会先在本地路径生成一份，再从本地导入到远程后，清除本地路径，但会保留文件夹


* **import_local_path**

* 描述：导入时导入数据文件的本地地址
* 必填：否
* 默认值：无,根据实际情况进行填写
* 注：import_local_path可不填写。未填写时，默认路径为目标数据库服务器配置用户根目录下的dataMigration


* **import_remote_path**

* 描述：导入时导入数据文件的远程地址，需填写ip(远程服务器IP)，port(远程服务器端口，默认为22)，username(服务器用户名)，password(服务器密码)，path(导入文件路径)
* 必填：否
* 默认值：无,根据实际情况进行填写
* 注：导入路径需要配置到库往上一层路径.如同时配置import_local_path和import_remote_path，则会按照映射要求导入到目标数据库中
* 如：1.地址为/data/hahaha/dataMigration/库名/tableName.dat，则需要配置到/data/haha
2.如果import_local_path和import_remote_path均配置，则先将远程地址文件拷到本地，再执行。(有相同文件则覆盖)

-----------------------------------------------------------------------------------------------------------------------------------------------
option中选项可直接执行默认配置，如有特殊需求，可根据说明进行更改

* **column_separator**

* 描述：数据分割符
* 必填：是
* 默认值：~~~~~
* 注：由于load工具对分隔符有一定要求，建议在非特殊情况下使用默认分隔符


* **row_separator**

* 描述：行分隔符
* 必填：是
* 默认值：@#\n#@
* 注：由于load工具对分隔符有一定要求，建议在非特殊情况下使用默认分隔符


* **data_check_type**

* 描述：数据校验方式,当前仅支持1(行级校验)
* 必填：是
* 默认值：1


* **compression_before_translate**

* 描述：是否压缩
* 必填：是
* 默认值：false


* **disable_foreign_key**

* 描述：导入数据前是否需要先消除外键，如消除，则在导入完成后会重新开启消除的外键
* 必填：是
* 默认值：true	


* **check_ddl**

* 描述：校验源库和目标库需要处理的表的字段名是否一致、字段类型是否兼容
* 必填：是
* 默认值：true


* **delete_file**

* 描述：导入成功后删除本地文件
* 必填：是
* 默认值：true	


* **ignore_lost_table**

* 描述：是否忽略目标库不存在的表（1.忽略 2.不忽略 3.如目标库不存在该表则自动创建）
* 必填：是
* 默认值：2


* **disable_trigger**

* 描述：禁用触发器。导入前判断是否需要禁用触发器，如禁用，导入完成后重新启用禁用的触发器
* 必填：是
* 默认值：true


* **import_nologging**

* 描述：是否使用nologging方式导入；true，导入完成后rebuild索引
* 必填：是
* 默认值：true


* **import_threads_per_obj**

* 描述：导入一个表的并发数，范围1~100
* 必填：是
* 默认值：10


* **import_total_task**

* 描述：导入时表级并发数，范围1~100(在目标数据库服务器进入/etc/ssh/sshd_config文件查看连接数最大值，当前配置值不可大于该值)
* 必填：是
* 默认值：5	


* **import_allow_max_errors**

* 描述：导入单表允许的最大失败行数，范围>=0
* 必填：是
* 默认值：0


* **import_force**

* 描述：导入失败仍然继续执行
* 必填：是
* 默认值：false


* **import_check_row_count**

* 描述：导入校验是否需要count目标表
* 必填：是
* 默认值：false	


* **truncate_before_import_db_data**

* 描述：导入数据前是否需要truncate目标表
* 必填：是
* 默认值：true


* **export_total_task**

* 描述：导出时表级并发数，范围1~100(在源数据库服务器进入/etc/ssh/sshd_config文件查看连接数最大值，当前配置值不可大于该值)
* 必填：是
* 默认值：10


* **export_allow_max_errors**

* 描述：导出单表允许的最大失败行数，范围>=0
* 必填：是
* 默认值：0


* **export_force**

* 描述：导出失败仍然继续执行
* 必填：是
* 默认值：false	


* **export_check_row_count**

* 描述：导出校验是否需要count源表
* 必填：是
* 默认值：false


* **export_append_on**

* 描述：支持多次导出数据一次性导入
* 必填：是
* 默认值：false
* 注：若无需多次导入，一次导出，则必须更改为false。且第一次配置为true时需要清除包下的ddlResult文件夹，以防止将不需要的数据导入。


* **export_max_rownum**

* 描述：每个表导出的最大行数:-1表示导出所有行，范围>=0
* 必填：是
* 默认值：-1

### exp_obj.ini参数说明

用户可以指定库或者表做数据迁移。
```
导出/导入的库配置，格式为：
db源名称[.表的名称] [:db映射的新名称.映射的表名] [过滤条件]
db源名称[.表的名称] [:db映射的新名称] [过滤条件]….
1） 中括号是可选内容
2) 过滤条件放在映射的新名称或表名的后边以空格隔开
3) 每一个映射关系占一行
4) 将映射关系添加到参数说明上方的空白处即可
5) 如不配置新映射，则默认源数据库的库名和表明，在目标数据库也是相同名称
6) 如要添加过滤条件，必须以where或者order by 开头
7) 只做导出时，库和表可进行模糊匹配。如haha%，则表示导出以haha开头的所有库
注：1.如不添加任何表则表示导出源数据库中的所有表（不包含系统表，临时表),如果配置导出条件，必须以where/order by开头
2.oracle默认不区分大小写，因此库名和表名需全大写
3.sybase和mysql默认区分大小写，因此需要跟创建库和表的大小写一致
例如:db1
db2 表示只导db1和db2，如果没有加":"则表示导入库里的库名和表名与导出库名及表明一致

db1:db3
db2 表示导出db1和db2，同时db1映射到db3;未配置表示所有库都要处理；如果是导入的流程则表示要处理的导入的库。 

db1.t_test
db2.t_test2:db3.t_test3 where rownum<=10 指定表时可以带条件,条件必须以where或order by开头，并且过滤条件只针对导出，导入不起作用
```

### exclusive_obj.ini 参数说明
```
当用户迁移数据是有些数据没必要进行迁移，用户可以自己配置排除这些库和表。

不导入/不导出库和表的配置，格式为：
db源名称[.表的名称]
1) 中括号是可选内容
2) 多个条件用逗号隔开
3) 将不导入的库和表添加到参数说明上方的空白处即可
注：如不添加任何表则表示导出源数据库中的所有表（不包含系统表，临时表）
例如:db1,db2 表示不导入db1库和db2库
db1.t_test,db2.t_test2 表示不导入db1库的t_test表和db2库的t_test表
```
